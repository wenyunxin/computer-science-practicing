[toc]

# Why 2015 was a breakthrough year in Artificial Intelligence

Computers are “starting to open their eyes,” said a senior fellow at Google.

[source link](https://web.archive.org/web/20161123053855/https://www.bloomberg.com/news/articles/2015-12-08/why-2015-was-a-breakthrough-year-in-artificial-intelligence) 

Jack Clark

December 8, 2015 — 8:00 AM EST December 10, 2015 — 2:45 PM EST

After a half-decade of quiet breakthroughs in artificial intelligence, 2015 has been a landmark year. Computers are smarter and learning faster than ever.

> 在人工智能领域悄无声息地突破了五年之后，2015年是一个具有里程碑意义的年份。计算机比以前更聪明，学习速度也更快。

The pace of advancement in AI is "actually speeding up," said Jeff Dean, a senior fellow at Google. To celebrate their achievements and plot the year ahead, Dean and many of the other top minds in AI are convening in Montreal this week at the Neural Information Processing Systems conference. It started in 1987 and has become a must-attend event for many Silicon Valley companies in the last few years, thanks to the explosion in AI. NIPS was where Facebook Chief Executive Officer Mark Zuckerberg chose in 2013 to announce the company's plans to form an AI laboratory and where a startup named DeepMind showed off an AI that could learn to play computer games before it was acquired by Google.

> 谷歌的高级研究员杰夫-迪安说，人工智能的进步速度 "实际上正在加快"。为了庆祝他们的成就和规划未来的一年，迪恩和其他许多人工智能领域的顶尖人物本周将在蒙特利尔召开神经信息处理系统会议。该会议始于1987年，在过去的几年里，由于人工智能的爆炸性增长，它已经成为许多硅谷公司必须参加的活动。2013年，Facebook首席执行官马克-扎克伯格(Mark Zuckerberg)选择在NIPS上宣布该公司组建人工智能实验室的计划，一家名为DeepMind的初创公司在被谷歌收购之前也在这里展示了能够学习玩电脑游戏的人工智能。

There should be plenty to discuss this week. The unprecedented advancements in AI research this year can be attributed to a confluence of nerdy factors. For one, cloud computing infrastructure is vastly more powerful and affordable, with the ability to process complex information. There are also more plentiful datasets and free or inexpensive software development tools for researchers to work with. Thanks to this, a crucial class of learning technology, known as neural networks, have gone from being prohibitively expensive to relatively cheap.

> 本周应该有很多东西可以讨论。今年人工智能研究的空前进步可以归功于一系列书呆子因素的汇合。首先，云计算基础设施的功能大大增强，而且价格低廉，具有处理复杂信息的能力。还有更丰富的数据集和免费或廉价的软件开发工具供研究人员使用。得益于此，一类关键的学习技术，即神经网络，已经从令人望而却步的昂贵变为相对便宜。

That's led to rapid uptake by the tech industry's largest companies, including Google, Facebook, and Microsoft. Each operates its own AI lab that conducts important research in the field and publishes much of it for the academic community to build upon. This year, Google researchers nabbed the cover of scientific journal *Nature* with a system that can learn to [play and master old Atari games](https://web.archive.org/web/20161123053855/http://www.bloomberg.com/news/articles/2015-02-25/google-s-computers-learn-to-play-video-games-by-themselves) without directions. Facebook built a way to let computers describe images to blind people; Microsoft showed off a new Skype system that can automatically translate from one language to another; and IBM singled out AI as one of its greatest potential growth areas.

> 这导致了科技行业最大的公司，包括谷歌、Facebook和微软的快速吸收。每个公司都有自己的人工智能实验室，在该领域进行重要的研究，并发表其中的大部分内容供学术界借鉴。今年，谷歌的研究人员在科学杂志《自然》（*Nature*）的封面上刊登了一个系统，该系统可以在没有指导的情况下学习[玩和掌握旧的雅达利游戏](https://web.archive.org/web/20161123053855/http://www.bloomberg.com/news/articles/2015-02-25/google-s-computers-learn-to-play-video-games-by-themselves)。脸书建立了一种让计算机向盲人描述图像的方法；微软展示了一个新的Skype系统，可以自动将一种语言翻译成另一种语言；而IBM则将人工智能作为其最大的潜在增长领域之一。

Startups are also contributing meaningfully to AI. Preferred Networks is [making AI systems](https://web.archive.org/web/20161123053855/http://www.bloomberg.com/news/articles/2015-12-03/zero-to-expert-in-eight-hours-these-robots-can-learn-for-themselves) that will go into industrial robots made by Japan's Fanuc, and Indico Data Labs worked with a Facebook researcher to teach a computer [how to paint faces](https://web.archive.org/web/20161123053855/http://www.bloomberg.com/news/articles/2015-12-02/computers-learn-how-to-paint-whatever-you-tell-them-to) using its own sort of imagination.

> 初创企业也在为人工智能做出有意义的贡献。Preferred Networks正在[制造人工智能系统](https://web.archive.org/web/20161123053855/http://www.bloomberg.com/news/articles/2015-12-03/zero-to-expert-in-eight-hours-these-robots-can-learn-for-themselves)，该系统将用于日本Fanuc公司制造的工业机器人。Indico Data Labs与Facebook的一名研究员合作，利用自己的想象力教计算机[如何画脸](https://web.archive.org/web/20161123053855/http://www.bloomberg.com/news/articles/2015-12-02/computers-learn-how-to-paint-whatever-you-tell-them-to) 。

For a look at how far computer intelligence has come this year, here are six charts that should give you a clearer picture.

> 要了解计算机智能在今年取得了多大的进展，这里有六张图表，应该能让你更清楚地了解。



<img src="../reference pics/error drop down.png">



<img src="../reference pics/al learns to pin.png">

Computers have become a lot better at figuring out what's in a photo. In 2012, a team of University of Toronto researchers won the world's top image-recognition competition. The entire team was eventually recruited by Google, and its approach was quickly adopted by the company and its peers. In 2015, AI systems based on the project's approach, which relies on a technique called deep learning, have become much more accurate. In tests, error rates are down to less than 5 percent, making them better than some humans' performances.

> 计算机在弄清照片中的内容方面已经做得很好。2012年，多伦多大学的一个研究团队赢得了世界顶级的图像识别比赛。整个团队最终被谷歌招募，其方法很快被该公司及其同行采用。2015年，基于该项目方法的人工智能系统已经变得更加准确，该方法依赖于一种叫做深度学习的技术。在测试中，错误率下降到5%以下，使其比一些人类的表现更好。



<img src="../reference pics/ai takes off at goole.png">

Lots of companies are embracing AI, perhaps none more than Google. The Internet giant went from sporadic usage of deep learning in 2012 to applying it to thousands of projects this year.

> 很多公司都在拥抱人工智能，也许没有人比谷歌更喜欢。这个互联网巨头从2012年零星使用深度学习，到今年将其应用于数千个项目。



<img src="../reference pics/companies buy more data to build ai systems.png">



<img src="../reference pics/computers get better at browsing the web with ai.png">

Startups are adopting AI in big ways, too. CrowdFlower, which supplies structured data to companies, said it has seen a dramatic uptick in the amount of data being requested by businesses to help them conduct AI research. DiffBot, another startup, is using AI to improve its automated data-scraping tools.

> 初创企业也在以大的方式采用人工智能。向企业提供结构化数据的CrowdFlower说，它看到企业要求的数据量急剧上升，以帮助他们进行人工智能研究。另一家创业公司DiffBot正在使用人工智能来改进其自动数据采集工具。

play it again hal

<img src="../reference pics/play it again hal.png">

A main focus of AI research is in teaching computers to think for themselves and improvise solutions to common problems. One way to do that is to give them a slimmed-down version of the real world, such as the simplified environments presented in video games, then ask them to explore it and record the results. (Check out the chart above for a look at how far Google's Atari project has come since 2013.) But the potential goes beyond games: Similar software could be used to teach things to AI computers and help them more quickly learn such new things as medical diagnostics, environmental science, or improved personal recommendations.

> 人工智能研究的一个主要重点是教计算机自己思考并即兴解决常见的问题。做到这一点的一个方法是给他们一个缩小版的真实世界，如视频游戏中呈现的简化环境，然后要求他们探索它并记录结果。(请看上面的图表，看看谷歌的阿塔里项目自2013年以来取得了多大的进展）。但其潜力超越了游戏。类似的软件可用于向人工智能计算机传授知识，帮助它们更快学会诸如医疗诊断、环境科学或改进的个人建议等新事物。

Google's Dean likens recent advancements in AI capabilities to evolution. "We're at this point in actual evolution where, previously, animals didn't have eyes, and now they have eyes," he said. "That's going to change a lot of stuff. Computers used to not be able to see very well, and now they're starting to open their eyes."

> 谷歌的迪安将最近在人工智能能力方面的进步比作进化。"我们正处于实际进化的这一阶段，以前，动物没有眼睛，而现在它们有眼睛，"他说。"这将会改变很多东西。计算机过去不能看得很清楚，而现在它们开始睁开眼睛了。"

---



# Understanding all Python, through its builtins

[article source link](https://sadh.life/post/builtins/#index)

Python has a whole lot of builtins that are unknown to most people. This guide aims to introduce you to everything that Python has to offer,  through its seemingly obscure builtins.

> Python 有一大堆大多数人都不知道的**内置程序**。本指南旨在通过看似晦涩的内置程序，向你介绍Python所能提供的一切。

Python as a language is comparatively simple. And I believe, that you  can learn quite a lot about Python and its features, just by learning  what all of its builtins are, and what they do. And to back up that  claim, I'll be doing just that.

> 作为一种语言，Python 是**比较**简单的。我相信，仅仅通过了解它的所有内建程序和它们的作用，你就可以学到很多关于 Python 和它的**特性**。为了支持这一主张，我将会这样做。

Just to be clear, this is not going to be a tutorial post. Covering such a vast amount of material in a single blog post, while starting from  the beginning is pretty much impossible. So I'll be assuming you have a  basic to intermediate understanding of Python. But other than that, we  should be good to go.

> 我想说的是，这不是一篇教程文章。在一篇博文中涵盖如此大量的材料，同时从头开始，这几乎是不可能的。所以我将假设你对Python有**基本到中等**程度的了解。但除此以外，我们应该可以开始了。

## So what's a builtin?

A builtin in Python is everything that lives in the `builtins` module.

To understand this better, you'll need to learn about the **L.E.G.B.** rule.

^ This defines the order of scopes in which variables are looked up in Python. It stands for:

- **L**ocal scope
- **E**nclosing (or nonlocal) scope
- **G**lobal scope
- **B**uiltin scope

> Python 中的**内置程序**是住在 `builtins` 模块中的所有东西。
>
> 为了更好地理解这一点，你需要学习**L.E.G.B.**规则。
>
> ^这定义了Python中**变量被查询**的作用域顺序（注：这是从当前函数/类的局部作用域里的**局域变量**的角度出发的顺序，从这个角度看，**E**nclosing (或nonlocal) 作用域可能存在或不存在，因为**E**nclosing (或nonlocal) 作用域是相对于嵌套函数/类而存在的）。它代表的是：
>
> - **L**局部作用域
> - **E**nclosing (或nonlocal) 作用域
> - **G**全局作用域
> - **B**uiltin scope（内置作用域）
>

### Local scope

The local scope refers to the scope that comes with the current  function or class you are in. Every function call and class  instantiation creates a fresh local scope for you, to hold local  variables in.

Here's an example:

> 局部作用域指的是你**当前所在的函数或类**所附带的作用域。每个函数的调用和类的实例化都会为你创建一个新的局部作用域，用来**保存局部变量**。
>
> 下面是一个例子：

```Python
x = 11
print(x)

def some_function():
    x = 22
    print(x)
    
some_function()

print(x)
```

Running this code outputs:

```python
11
22
11
```

So here's what's happening: Doing `x = 22` defines a new variable inside `some_function` that is in its own **local namespace**. After that point, whenever the function refers to `x`, it means the one in its own scope. Accessing `x` outside of `some_function` refers to the one defined outside.

> 所以这里发生了什么。做`x = 22`在`some_function`中定义了一个**新**的变量，这个变量在它自己的**局域命名空间**中。在这之后，只要函数引用到`x`，就是指它自己作用域内的那个。在`some_function`之外访问`x`是指在函数**外面**定义的那个。

### Enclosing scope

The enclosing scope (or nonlocal scope) refers to the scope of the  classes or functions inside which the current function/class lives.

... I can already see half of you going 🤨 right now. So let me explain with an example:

> 闭合作用域（或nonlocal作用域）是指当前函数/类所在的类或函数的作用域。
>
> ... 我已经可以看到你们中的一半人现在正在🤨。所以让我用一个例子来解释：

```Python
x = 11
# out_function的作用域从它自身的角度看，它是局域作用域，从inner_function的角度看，它是闭合作用域；函数还可以再嵌套，那么从整个模块的视角看，最内层的函数的作用域是局域作用域，嵌套着该函数的函数的作用域是闭合作用域
def outer_function():
    x = 22
    y = 789
    
    def inner_function():
        x = 33
        print('Inner x:', x)
        print('Enclosing y:', y)
        
    inner_function()
    print('Outer x:', x)
    
outer_function()
print('Gloabal x:', x)
```

The output of this is:

```python
Inner x: 33
Enclosing y: 789
Outer x: 22
Global x: 11
```

What it essentially means is that every new function/class creates its own local scope, **separate from its outer environment**. Trying to access an outer variable will work, but any variable created  in the local scope does not affect the outer scope. This is why  redefining x to be `33` inside the inner function doesn't affect the outer or global definitions of `x`.

> But what if I want to affect the outer scope?

To do that, you can use the `nonlocal`  keyword in Python to tell the interpreter that you don't mean to define a new variable in the local scope, but you want to modify the one in the  enclosing scope.

> 它的本质含义是，每个新的函数/类都会**创建自己的局部作用域**，**与它的外部环境分开**。试图访问外部变量会起作用，但在局部作用域中创建的任何变量都不会影响外部作用域。这就是为什么在内部函数中重新定义x为`33`不会影响`x`的外部或全局定义。
>
> > 但如果我想影响外部作用域呢？
>
> 要做到这一点，你可以使用 Python 中的 `nonlocal` 关键字来告诉解释器，你不是想在局部作用域中定义一个新的变量，而是想修改**闭合作用域中**的变量。

```python
# out_function的作用域从它自身的角度看，它是局域作用域，从inner_function的角度看，它是闭合作用域；函数还可以再嵌套，那么从整个模块的视角看，最内层的函数的作用域是局域作用域，嵌套着该函数的函数的作用域是闭合作用域
def outer_function():
    x = 11
    
    def inner_function():
        # 修改闭合作用域的x
        nonlocal x
        x = 22
        print('Inner x:', x)
        
    inner_function()
    print('Outer x:', x)
```

This prints:

```python
Inner x: 22
Outer x: 22
```

### Global scope

Global scope (or module scope) simply refers to the scope where all  the module's top-level variables, functions and classes are defined.

A "module" is any python file or package that can be run or imported. For eg. `time` is a module (as you can do `import time` in your code), and `time.sleep()` is a function defined in `time` module's global scope.

Every module in Python has a few pre-defined globals, such as `__name__` and `__doc__`, which refer to the module's name and the module's docstring, respectively. You can try this in the REPL:

> **全局作用域**（或**模块**作用域）简单地说就是指模块的所有**顶层变量**、**函数**和**类**被定义所在地方的作用域。
>
> 一个 "模块 "是任何可以运行或导入的**python文件**或**包**。例如，`time`是一个模块（因为你可以在你的代码中做`import time`），而`time.sleep()`是定义在`time`模块的全局作用域内的一个函数。
>
> Python 中的每个模块都有一些**预定义**的全局变量，例如 `__name__` 和 `__doc__ `，它们分别指的是模块的**名称**和模块的 **docstring**。你可以在 REPL 中试试这个：

```python
>>> print(__name__)
__main__
>>> print(__doc__)
None
>>> import time
>>> time.__name__
'time'
>>> time.__doc__
'This module provides various functions to manipulate time values.'
```

### Builtin scope

Now we get to the topic of this blog -- the builtin scope.

So there's two things to know about the builtin scope in Python:

- It's the scope where essentially all of Python's top level functions are defined, such as `len`, `range` and `print`.
- When a variable is not found in the local, enclosing or global scope, Python looks for it in the builtins.

You can inspect the builtins directly if you want, by importing the `builtins` module, and checking methods inside it:

> 现在我们开始讨论本博客的**主题** -- **内置作用域**。
>
> 关于 Python 中的内置作用域，有两件事需要了解：
>
> - 它是定义所有 Python **顶级函数**的作用域，例如 `len`, `range` 和 `print`。
> - 当一个变量在局部、闭合或全局作用域中没有找到时，Python 会在内置作用域中寻找它。（变量的最后搜索作用域）
>
> 如果你想的话，可以**直接检查**内置函数，方法是导入 `builtins` 模块，并检查其中的方法：

```python
import builtins
```

And for some reason unknown to me, Python exposes the builtins module as `__builtins__` by default in the global namespace. So you can also access `__builtins__` directly, without importing anything. Note, that `__builtins__` being available is a CPython implementation detail, and other Python implementations might not have it. `import builtins` is the most correct way to access the builtins module.

> 由于一些我不知道的原因，Python 在全局命名空间中默认将 buildins 模块作为 `__builtins__` 曝露。所以你也可以直接访问 `__builtins__`，而不用导入任何东西。注意，`__builtins__`的可用性是CPython实现的一个细节，其他Python实现可能没有这个功能。`import builtins`是访问buildins模块的**最正确的方法**。

## All the builtins

You can use the `dir` function to print all the variables defined inside a module or class. So let's use that to list out all of the builtins:

> （dir可用来呈现任何Python对象所包含的变量）你可以使用`dir`函数来打印一个模块或类中定义的**所有变量**。所以让我们用它来列出所有的内置模块：

```python
print(dir(builtins))
['ArithmeticError', 'AssertionError', 'AttributeError', 'BaseException', 'BlockingIOError', 'BrokenPipeError', 'BufferError', 'BytesWarning', 'ChildProcessError', 'ConnectionAbortedError', 'ConnectionError', 'ConnectionRefusedError', 'ConnectionResetError', 'DeprecationWarning', 'EOFError', 'Ellipsis', 'EncodingWarning', 'EnvironmentError', 'Exception', 'False', 'FileExistsError', 'FileNotFoundError', 'FloatingPointError', 'FutureWarning', 'GeneratorExit', 'IOError', 'ImportError', 'ImportWarning', 'IndentationError', 'IndexError', 'InterruptedError', 'IsADirectoryError', 'KeyError', 'KeyboardInterrupt', 'LookupError', 'MemoryError', 'ModuleNotFoundError', 'NameError', 'None', 'NotADirectoryError', 'NotImplemented', 'NotImplementedError', 'OSError', 'OverflowError', 'PendingDeprecationWarning', 'PermissionError', 'ProcessLookupError', 'RecursionError', 'ReferenceError', 'ResourceWarning', 'RuntimeError', 'RuntimeWarning', 'StopAsyncIteration', 'StopIteration', 'SyntaxError', 'SyntaxWarning', 'SystemError', 'SystemExit', 'TabError', 'TimeoutError', 'True', 'TypeError', 'UnboundLocalError', 'UnicodeDecodeError', 'UnicodeEncodeError', 'UnicodeError', 'UnicodeTranslateError', 'UnicodeWarning', 'UserWarning', 'ValueError', 'Warning', 'WindowsError', 'ZeroDivisionError', '_', '__build_class__', '__debug__', '__doc__', '__import__', '__loader__', '__name__', '__package__', '__spec__', 'abs', 'aiter', 'all', 'anext', 'any', 'ascii', 'bin', 'bool', 'breakpoint', 'bytearray', 'bytes', 'callable', 'chr', 'classmethod', 'compile', 'complex', 'copyright', 'credits', 'delattr', 'dict', 'dir', 'divmod', 'enumerate', 'eval', 'exec', 'exit', 'filter', 'float', 'format', 'frozenset', 'getattr', 'globals', 'hasattr', 'hash', 'help', 'hex', 'id', 'input', 'int', 'isinstance', 'issubclass', 'iter', 'len', 'license', 'list', 'locals', 'map', 'max', 'memoryview', 'min', 'next', 'object', 'oct', 'open', 'ord', 'pow', 'print', 'property', 'quit', 'range', 'repr', 'reversed', 'round', 'set', 'setattr', 'slice', 'sorted', 'staticmethod', 'str', 'sum', 'super', 'tuple', 'type', 'vars', 'zip']
```

...yeah, there's a lot. But don't worry, we'll break these down into various groups, and knock them down one by one.

So let's tackle the biggest group by far:

> ...是的，有很多。但是别担心，我们会把这些东西分成**不同的组别**，并逐一击倒。
>
> 因此，让我们来解决迄今为止**最大的一组**：

## Exceptions

Python has 66 built-in exception classes (so far), each one intended  to be used by the user, the standard library and everyone else, to serve as meaningful ways to interpret and catch errors in your code.

To explain exactly why there's separate Exception classes in Python, here's a quick example:

> Python 有 66 个**内置的异常类** (到目前为止)，每一个都是为了让用户、标准库和其他所有人使用，作为**解释和捕捉**代码中的错误的有意义的方法。
>
> 为了准确解释为什么在Python中有**单独的**异常类，这里有一个快速的例子：

```python
def fetch_from_cache(key):
    """Returns a key's value from cached items."""
    if key is None:
        raise ValueError('key must not to be None')
        
    return cached_items[key]

def get_value(key):
    try:
        value = fetch_from_cache(key)
    except KeyError:
        value = fetch_from_api(key)
        
    return value
```

Focus on the `get_value` function. It's supposed to return a cached value if it exists, otherwise fetch data from an API.

There's 3 things that can happen in that function:

- If the `key` is not in the cache, trying to access `cached_items[key]` raises a `KeyError`. This is caught in the `try` block, and an API call is made to get the data.

- If they `key` *is* present in the cache, it is returned as is.

- There's also a third case, where `key` is `None`.

  If the key is `None`, `fetch_from_cache` raises a `ValueError`, indicating that the value provided to this function was inappropriate. And since the `try` block only catches `KeyError`, this error is shown directly to the user.

> 重点是`get_value`函数。它应该返回一个缓存的值，如果它存在，否则从API获取数据。
>
> 在这个函数中，有3种情况可能发生。
>
> - 如果 `key` 不在缓存中，试图访问 `cached_items[key]` 会引发一个 `KeyError`。这将在 `try` 块中被捕获，并调用API来获取数据。
>
> - 如果他们的 `key` *存在*于缓存中，它将被原样返回。
>
> - 还有第三种情况，`key`是`None`。
>
>   如果key是`None`，`fetch_from_cache`会引发`ValueError`，表明提供给这个函数的值是不合适的。由于`try`块只捕捉到`KeyError`，这个错误会直接显示给用户。

```python
>>> x = None
>>> get_value(x)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 3, in get_value
  File "<stdin>", line 3, in fetch_from_cache
ValueError: key must not be None
>>>
```

If `ValueError` and `KeyError` weren't predefined, meaningful error types, there wouldn't be any way to differentiate between error types in this way.

> 如果 `ValueError` 和 `KeyError` 不是预定义的、有意义的错误类型，就没有办法用这种方式来区分错误类型。

> Extras: Exception trivia
>
> A fun fact about exceptions is that they can be sub-classed to make  your own, more specific error types. For example, you can create a `InvalidEmailError` extending `ValueError`, to raise errors when you expected to receive an E-mail string, but it wasn't valid. If you do this, you'll be able to catch `InvalidEmailError` by doing `except ValueError` as well.
>
> Another fact about exceptions is that every exception is a subclass of `BaseException`, and nearly all of them are subclasses of `Exception`, other than a few that aren't supposed to be normally caught. So if you  ever wanted to be able to catch any exception normally thrown by code,  you could do
>
> > 关于异常的一个有趣的事实是，它们可以**被子类化**，以形成你自己的、**更具体的**错误类型。例如，你可以创建一个 `InvalidEmailError` 来扩展 `ValueError`，当你期望收到一个E-mail字符串，但它不是有效的，就会产生错误。如果你这样做，你就可以通过做`except ValueError`来捕获`InvalidEmailError`。
> >
> > 关于异常的另一个事实是，每一个异常都是`BaseException`的**子类**，而且几乎所有的异常都是`Exception`的**子类**，除了一些不应该被正常捕获的异常。因此，如果你想捕捉任何通常由代码抛出的异常，你可以这样做
>
> ```python
> except Exception: ...
> ```
>
> and if you wanted to catch *every possible error*, you could do
>
> ```python
> except BaseException: ...
> ```
>
> Doing that would even catch `KeyboardInterrupt`, which would make you unable to close your program by pressing `Ctrl+C`. To read about the hierarchy of which Error is subclassed from which in Python, you can check the [Exception hierarchy](https://docs.python.org/3/library/exceptions.html#exception-hierarchy) in the docs.
>
> > 这样做甚至会捕捉到`KeyboardInterrupt`，这将使你无法通过按`Ctrl+C`来关闭你的程序。要阅读Python中哪个Error是由哪个子类组成的层次结构，你可以查看文档中的 [Exception hierarchy](https://docs.python.org/3/library/exceptions.html#exception-hierarchy)。

Now I should point out that not *all* uppercase values in that  output above were exception types, there's in-fact, 1 another type of  built-in objects in Python that are uppercase: constants. So let's talk  about those.

> 现在我应该指出，在上面的输出中，并非*所有*大写的值都是异常类型，事实上，在Python中还有一类**内置对象**是大写的：**常量**。所以我们来谈谈这些。

## Constants

There's exactly 5 constants: `True`, `False`, `None`, `Ellipsis`, and `NotImplemented`.

`True`, `False` and `None` are the most obvious constants.

`Ellipsis` is an interesting one, and it's actually represented in two forms: the word `Ellipsis`, and the symbol `...`. It mostly exists to support [type annotations](https://sadh.life/post/mypy-guide), and for some very fancy slicing support.

`NotImplemented` is the most interesting of them all *(other than the fact that `True` and `False` actually function as `1` and `0` if you didn't know that, but I digress)*. `NotImplemented` is used inside a class' operator definitions, when you want to tell  Python that a certain operator isn't defined for this class.

Now I should mention that all objects in Python can add support for all Python operators, such as `+`, `-`, `+=`, etc., by defining special methods inside their class, such as `__add__` for `+`, `__iadd__` for `+=`, and so on.

Let's see a quick example of that:

> 有5个**常数**：`True`, `False`, `None`, `Ellipsis`, 和`NotImplemented`。
>
> `True`, `False`和`None`是**最明显的**常数。
>
> `Ellipsis`是一个有趣的常数，它实际上以两种形式表示：单词`Ellipsis`，和符号`...`。它的存在主要是为了支持[类型注释](https://sadh.life/post/mypy-guide)，以及一些非常花哨的**切分支持**。
>
> `NotImplemented`是其中最有趣的*（除了`True`和`False`实际上作为`1`和`0`的功能外，如果你不知道的话，但我想不会的）*。`NotImplemented`在一个类的**操作符定义**中使用，当你想告诉Python某个操作符**没有为这个类定义**。
>
> 现在我应该提到，Python 中的所有对象都可以通过在它们的类中定义特殊的方法来增加对所有 Python 操作符的支持，如`+`、`-`、`+=`等等，如`+`的`__add__`、`+=`的`__iadd__`，等等。
>
> 让我们看一个简单的例子：

```python
class MyNumber:
    def __add__(self, other):
        return other + 42
```

This results in our object acting as the value `42` during addition:

> 这导致我们的对象在加法过程中充当值`42`：

```python
num = MyNumber()
num + 3
45
num + 100
142
```

> Extras: right-operators
>
> If you're wondering from the code example above why I didn't try to do `3 + num`, it's because it doesn't work yet:
>
> > 如果你从上面的代码例子中想知道为什么我没有尝试做`3 + num`，那是因为它还不能工作。
>
> ```python
> 100 + num
> Traceback (most recent call last):
>   File "<stdin>", line 1, in <module>
> TypeError: unsupported operand type(s) for +: 'int' and 'MyNumber'
> ```
>
> But, support for that can be added pretty easily by adding the `__radd__` operator, which adds support for *right-addition*:
>
> > 但是，通过添加`__radd__`操作符，可以很容易地增加对它的支持，它增加了对*右加*的支持：
>
> ```python
> class MyNumber:
>     def __add__(self, other):
>         return other + 42
> 
>     def __radd__(self, other):
>         return other + 42
> ```
>
> As a bonus, this also adds support for adding two `MyNumber` classes together:
>
> ```python
> >>> num = MyNumber()
> >>> num + 100
> 142
> >>> 3 + num
> 45
> >>> num + num
> 84
> ```

But let's say you only want to support integer addition with this class, and not floats. This is where you'd use `NotImplemented`:

> 但假设你**只想用这个类来支持**整数加法，而不是浮点数。这就是你要使用`NotImplemented`的地方：

```python
class MyNumber:
    def __add__(self, other):
        if isinstance(other, float):
            return NotImplemented

        return other + 42
```

Returning `NotImplemented` from an operator method tells Python that this is an unsupported operation. Python then conveniently wraps this into a `TypeError` with a meaningful message:

> 从一个操作方法返回 `NotImplemented` 告诉 Python 这是一个不支持的操作。然后Python很方便地把它包装成一个带有有意义的消息的`TypeError`：

```python
>>> num + 0.12
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: unsupported operand type(s) for +: 'MyNumber' and 'float'
```

A weird fact about constants is that they aren't even implemented in Python, they're implemented directly in C code, like [this](https://github.com/python/cpython/blob/7e246a3/Include/object.h#L610) for example.

> 关于常数的一个奇怪的事实是，它们甚至没有在Python中实现，而是直接在C代码中实现，比如说[this](https://github.com/python/cpython/blob/7e246a3/Include/object.h#L610)例子。

## Funky globals

There's another group of odd-looking values in the [builtins output](https://sadh.life/post/builtins/#all-the-builtins) we saw above: values like `__spec__`, `__loader__`, `__debug__` etc.

These are actually not unique to the `builtins` module. These properties are all present in the global scope of every module in Python, as they are *module attributes*. These hold information about the module that is required for the **import machinery**. Let's take a look at them:

> 在我们上面看到的 [builtins output](https://sadh.life/post/builtins/#all-the-builtins) 中还有一组看起来很奇怪的值：像 `__spec__`, `__loader__`, `__debug__` 等等。
>
> 这些实际上不是 `builtins` 模块所独有的。这些属性都存在于 Python 中**每个模块**的全局作用域内，因为它们是*模块属性*。这些持有关于模块的信息，这些信息是**导入机制**所需要的。让我们看一下它们：

### `__name__`

Contains the name of the module. For example, `builtins.__name__` will be the string `'builtins'`. When you run a Python file, that is also run as a module, and the module name for that is `__main__`. This should explain how `if __name__ == '__main__'` works when used in Python files.

> 包含**模块的名称**。例如，`builtins.__name__`将是字符串`'buildins'`。当你运行一个 Python 文件时，它也是**作为一个模块运行**的，它的模块名是 `__main__`。这应该解释了在 Python 文件中使用 `if __name__ == '__main__'` 时是如何工作的。

### `__doc__`

Contains the module's docstring. It's what's shown as the module description when you do `help(module_name)`.

> 包含模块的**文档字符串**。当你执行 `help(module_name)`时，它将显示为**模块的描述**。

```Python
import time
print(time.__doc__)
This module provides various functions to manipulate time values.

There are two standard representations of time.  One is the number...

help(time)

Help on built-in module time:

NAME
    time - This module provides various functions to manipulate time values.

DESCRIPTION
    There are two standard representations of time.  One is the number...
```

> More Python trivia: this is why the [PEP8 style guide](https://python.org/dev/peps/pep-0008) says "docstrings should have a line length of 72 characters": because docstrings can be indented upto two levels in the `help()` message, so to neatly fit on an 80-character wide terminal they must be at a maximum, 72 characters wide.
>
> 更多的 Python 琐事：这就是为什么 [PEP8 风格指南](https://python.org/dev/peps/pep-0008) 说 "文档字符串应该有 72 个字符的行长"：因为文档字符串在 `help()` 消息中最多可以**缩进两级**（每级4个字符，共8个字符），所以为了整齐地放在一个 80 字符宽的终端上，它们最多必须有 72 个字符宽。

### `__package__`

The package to which this module belongs. For top-level modules it is the same as `__name__`. For sub-modules it is the package's `__name__`. For example:

> 该模块所属的**包**。对于顶层模块，它与`__name__`相同。对于子模块，它是包的`__name__`。例如：

```python
import urllib.request
urllib.__package__
'urllib'
urllib.request.__name__
'urllib.request'
urllib.request.__package__
'urllib'
```

### `__spec__`

This refers to the module spec. It contains metadata such as the module  name, what kind of module it is, as well as how it was created and  loaded.

> 这指的是模块规格。它包含**元数据**，如**模块名称**，它是**什么类型**的模块，以及它是**如何创建**和**加载**的。
>

```python
$ tree mytest
mytest
└── a
    └── b.py

1 directory, 1 file

$ python -q
>>> import mytest.a.b
>>> mytest.__spec__
ModuleSpec(name='mytest', loader=<_frozen_importlib_external._NamespaceLoader object at 0x7f28c767e5e0>, submodule_search_locations=_NamespacePath(['/tmp/mytest']))
>>> mytest.a.b.__spec__
ModuleSpec(name='mytest.a.b', loader=<_frozen_importlib_external.SourceFileLoader object at 0x7f28c767e430>, origin='/tmp/mytest/a/b.py')
```

You can see through it that, `mytest` was located using something called `NamespaceLoader` from the directory `/tmp/mytest`, and `mytest.a.b` was loaded using a `SourceFileLoader`, from the source file `b.py`.

> 你可以通过它看到，`mytest`是用一个叫做`NamespaceLoader`的东西从`/tmp/mytest`目录中**定位**的，`mytest.a.b`是用一个`SourceFileLoader`加载的，来自源文件`b.py`。
>

### `__loader__`

Let's see what this is, directly in the REPL:

> 让我们看看这是什么，直接在REPL中：

```python
__loader__
<class '_frozen_importlib.BuiltinImporter'>
```

The `__loader__` is set to the loader object that the import machinery used when loading the module. This specific one is defined within the `_frozen_importlib` module, and is what's used to import the builtin modules.

Looking slightly more closely at the example before this, you might notice that the `loader` attributes of the module spec are `Loader` classes that come from the slightly different `_frozen_importlib_external` module.

So you might ask, what are these weird `_frozen` modules? Well, my friend, it's exactly as they say -- they're *frozen modules*.

The *actual* source code of these two modules is actually inside the `importlib.machinery` module. These `_frozen` aliases are frozen versions of the source code of these loaders. To  create a frozen module, the Python code is compiled to a code object,  marshalled into a file, and then added to the Python executable.

> `__loader__`被设置为**导入机制**在加载模块时使用的**加载器对象**。这个特定的对象是在`_frozen_importlib`模块中定义的，并且是用来**导入内置模块**的。
>
> 再仔细看看之前的例子，你可能会注意到模块spec的 "加载器" 属性是 "加载器"类，它来自稍微不同的"_frozen_importlib_external"模块。
>
> 所以你可能会问，这些奇怪的`_frozen`模块是什么？好吧，我的朋友，这正是他们所说的 -- 他们是*frozen*模块。
>
> 这两个模块的*实际*源代码实际上是在`importlib.machinery`模块里面。这些 `_frozen` 别名是这些加载器的源代码的frozen版本。为了创建一个frozen模块，Python 代码被编译成一个代码对象，**被编入**一个文件，然后添加到 Python 可执行文件中。

> If you have no idea what that meant, don't worry, we will cover this in detail later.
>
> > 如果你不知道这意味着什么，不要担心，我们以后会详细介绍。

Python freezes these two modules because they implement the core of  the import system and, thus, cannot be imported like other Python files  when the interpreter boots up. Essentially, they are needed to exist to *bootstrap the import system*.

Funnily enough, there's another well-defined frozen module in Python: it's `__hello__`:

> Python freezes这两个模块，因为它们**实现了导入系统的核心**，因此，在解释器启动时不能像其它 Python 文件一样被导入。从本质上讲，它们的存在是为了*bootstrap导入系统*。
>
> 有趣的是，在Python中还有一个定义明确的frozen模块：它就是`__hello__`：

```python
import __hello__
Hello world!
```

Is this the shortest hello world code in any language? :P

Well this `__hello__` module was originally added to Python as a test for frozen modules, to  see whether or not they work properly. It has stayed in the language as  an easter egg ever since.

> 这是任何语言中最短的hello world代码吗？ :P
>
> 这个`__hello__`模块最初被添加到Python中，作为对**冻结模块的测试**，以了解它们是否能正常工作。从那时起，它就作为一个复活节彩蛋留在了语言中。

### `__import__`

`__import__` is the builtin function that defines how import statements work in Python.

> `__import__`是内置函数，定义了**导入语句**在Python中的工作方式。

```python
import random
random
<module 'random' from '/usr/lib/python3.9/random.py'>

__import__('random')
<module 'random' from '/usr/lib/python3.9/random.py'>

np = __import__('numpy')  # Same as doing 'import numpy as np'
np
<module 'numpy' from '/home/tushar/.local/lib/python3.9/site-packages/numpy/__init__.py'>
```

Essentially, every import statement can be translated into an `__import__` function call. Internally, that's pretty much what Python is doing to the import statements (but directly in C).

> 从本质上讲，每个**导入语句**都可以被翻译成一个`__import__`函数调用。在内部，这几乎就是 Python 对 import 语句**所做的事情** (但直接用 C 语言)。

> Now, there's three more of these properties left: `__debug__` and `__build_class__` which are only present globally and are not module variables, and `__cached__`, which is only present in imported modules.
>
> > 现在，还剩下三个这样的属性：`__debug__`和`__build_class__`，它们**只存在于全局**，不是模块变量，以及`__cached__`，它只存在于**导入的模块中**。

### `__debug__`

This is a global, constant value in Python, which is almost always set to `True`.

What it refers to, is Python running in *debug mode*. And Python always runs in debug mode by default.

The other mode that Python can run in, is *"optimized mode"*. To run python in "optimized mode", you can invoke it by passing the `-O` flag. And all it does, is prevents assert statements from doing  anything (at least so far), which in all honesty, isn't really useful at all.

> 这是Python中的一个全局常数值，几乎总是被设置为 `True`。
>
> 它指的是Python运行在*调试模式*。而Python默认**总是运行在调试模式**下。
>
> 另一种Python可以运行的模式是*"优化模式 "*。要在 "优化模式 "下运行Python，你可以通过传递`-O`标志来调用它。它所做的就是阻止断言语句（assert statements）做任何事情（至少到目前为止），老实说，这一点都不实用：

```python
$ python
>>> __debug__
True
>>> assert False, 'some error'
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
AssertionError: some error
>>>

$ python -O
>>> __debug__
False
>>> assert False, 'some error'
>>> # Didn't raise any error.
```

Also, `__debug__`, `True`, `False` and `None` are the only **true constants** in Python, i.e. these 4 are the only global variables in Python that you cannot overwrite with a new value.

> 另外，`__debug__`、`True`、`False`和`None`是Python中唯一的**真常数**，也就是说，这4个是Python中唯一不**能用新值覆盖的全局变量**。

```python
>>> True = 42
  File "<stdin>", line 1
    True = 42
    ^
SyntaxError: cannot assign to True
>>> __debug__ = False
  File "<stdin>", line 1
SyntaxError: cannot assign to __debug__
```

### `__build_class__`

This global was added in Python 3.1, to allow for class definitions  to accept arbitrary positional and keyword arguments. There are long,  technical reasons to why this is a feature, and it touches advanced  topics like metaclasses, so unfortunately I won't be explaining why it  exists.

But all you need to know is that this is what allows you to do things like this while making a class:

> 这个全局是在 Python 3.1 中添加的，允许类的定义**接受任意的位置和关键字参数**。为什么这是一个功能，有很长的技术原因，而且它涉及到像**元类这样的高级话题**，所以不幸的是我不会解释它的存在原因。
>
> 但你需要知道的是，这是允许你在制作一个类时做这样的事情：
>

```python
>>> class C:
...     def __init_subclass__(self, **kwargs):
...         print(f'Subclass got data: {kwargs}')
...
>>> class D(C, num=42, data='xyz'):
...     pass
...
Subclass got data: {'num': 42, 'data': 'xyz'}
>>>
```

Before Python 3.1, The class creation syntax only allowed passing  base classes to inherit from, and a metaclass property. The new  requirements were to allow variable number of positional and keyword  arguments. This would be a bit messy and complex to add to the language.

But, we already have this, of course, in the code for calling regular functions. So it was proposed that the `Class X(...)` syntax will simply delegate to a function call underneath: `__build_class__('X', ...)`.

> 在Python 3.1之前，创建类的语法只允许**传递基类来继承**，以及一个元类属性。新的要求是允许可变数量的位置参数和关键字参数。这将是一个有点混乱和复杂的添加到语言中。
>
> 但是，在调用常规函数的代码中，我们当然已经有了这样的功能。所以有人提议，`Class X(...)`语法将简单地**委托**给下面的函数调用：`__build_class__('X', ...)`。
>

### `__cached__`

This is an interesting one.

When you import a module, the `__cached__` property stores the path of the cached file of the **compiled Python bytecode** of that module.

"What?!", you might be saying, "Python? Compiled?"

Yeah. Python *is* compiled. In fact, all Python code is compiled, but not to machine code -- to **bytecode**. Let me explain this point by explaining how Python runs your code.

> 这是个有趣的内建变量。
>
> 当你导入一个模块时，`__cached__`属性存储了该模块的**编译的Python字节码**的缓存文件的路径。
>
> "什么？"，你可能会说，"Python？编译的？"
>
> 是的。Python *是*编译的。事实上，所有的 Python 代码都被编译了，但不是编译成机器码--而是编译成**字节码**。让我通过解释 Python 如何运行你的代码来说明这一点。

Here are the steps that the Python interpreter takes to run your code:

- It takes your source file, and parses it into a syntax tree. The  syntax tree is a representation of your code that can be more easily  understood by a program. It finds and reports any errors in the code's  syntax, and ensures that there are no ambiguities.
- The next step is to compile this syntax tree into *bytecode*. Bytecode is a set of micro-instructions for **Python's virtual machine**. This "virtual machine" is where Python's interpreter logic resides. It essentially *emulates* a very simple stack-based computer on your machine, in order to execute the Python code written by you.
- This bytecode-form of your code is then run on the Python VM. The  bytecode instructions are simple things like pushing and popping data  off the current stack. Each of these instructions, when run one after  the other, executes the entire program.

> 下面是 Python **解释器**运行你的代码的**步骤**：
>
> - 它接收你的**源文件**，并将其**解析**为一个**语法树**。语法树是你的代码的表现，可以更容易被程序理解。它发现并报告代码语法中的任何错误，并**确保不存在歧义**。
> - 下一步是将这个语法树**编译**成*bytecode*。bytecode（字节码）是**Python的虚拟机**的一组微指令。这个 "虚拟机 "是 Python **解释器逻辑**所在的地方。它本质上是在你的机器上*模拟*一个非常简单的**基于堆栈**的计算机，以执行你编写的Python代码。
> - 你的代码的字节码形式然后在 Python VM 上运行。字节码指令是一些简单的东西，比如从当前堆栈中**推送和弹出数据**。这些指令中的每一条，当一个接一个地运行时，都会执行整个程序。
>

source file - syntax tree - bytecode - run by the Python VM

> We will take a really detailed example of the steps above, in the next section. Hang tight!
>
> 我们将以上述步骤为例，在下一节真正详细说明。坐稳!

Now since the "compiling to bytecode" step above takes a noticeable amount of time when you import a module, Python stores *(marshalls)* the bytecode into a `.pyc` file, and stores it in a folder called `__pycache__`. The `__cached__` parameter of the imported module then points to this `.pyc` file.

When the same module is imported again at a later time, Python checks if a `.pyc` version of the module exists, and then directly imports the  already-compiled version instead, saving a bunch of time and  computation.

If you're wondering: yes, you can directly run or import a `.pyc` file in Python code, just like a `.py` file:

> 现在，由于当你导入一个模块时，上面的 "编译为字节码 "步骤需要花费大量的时间，Python 将字节码*(marshalls)*存储到一个`.pyc`文件中，并将其存储在一个叫做`__pycache__`的文件夹中。然后导入模块的 `__cached__` 参数指向这个 `.pyc` 文件。
>
> 当以后再次导入同一个模块时，Python 会检查该模块的 `.pyc` 版本是否存在，然后直接导入已经**编译好**的版本，从而节省了大量的时间和**计算**。
>
> 如果你想知道：是的，你可以在 Python 代码中直接运行或导入一个 `.pyc` 文件，就像一个 `.py` 文件：

```python
>>> import test
>>> test.__cached__
'/usr/lib/python3.9/test/__pycache__/__init__.cpython-39.pyc'
>>> exit()

$ cp '/usr/lib/python3.9/test/__pycache__/__init__.cpython-39.pyc' cached_test.pyc
$ python
>>> import cached_test  # Runs!
>>>
```

## All the builtins, one by one

Now we can finally get on with builtins. And, to build upon the last  section, let's start this off with some of the most interesting ones,  the ones that build the basis of Python as a language.

> 现在我们终于可以继续讨论**内建程序**了。在上一节的基础上，让我们从一些最有趣的开始，那些建立在 Python 语言基础上的。

### `compile`, `exec` and `eval`: How the code works

In the previous section, we saw the 3 steps required to run some  python code. This section will get into details about the 3 steps, and  how you can observe exactly what Python is doing.

Let's take this code as an example:

> 在上一节中，我们看到了运行一些Python代码所需的3个步骤。本节将详细介绍这3个步骤，以及如何**准确观察**Python正在做什么。
>
> 让我们以这段代码为例：

```python
x = [1, 2]
print(x)
```

You can save this code into a file and run it, or type it in the Python REPL. In both the cases, you'll get an output of `[1, 2]`.

Or thirdly, you can give the program as a string to Python's builtin function `exec`:

> 你可以把这段代码**保存到一个文件**中并运行它，或者在Python REPL中输入它。在这两种情况下，你都会得到一个`[1, 2]`的输出。
>
> 第三，你可以把这个程序作为一个字符串交给Python的内置函数`exec`。

```python
code = '''
x = [1, 2]
print(x)
'''

exec(code)
```

`exec` (short for execute) takes in some Python code as a string, and runs it as Python code. By default, `exec` will run in the same scope as the rest of your code, which means, that  it can read and manipulate variables just like any other piece of code  in your Python file.

> `exec` (**execute**的缩写) **以字符串的形式**接收一些Python代码，并将其作为Python代码运行。默认情况下，`exec`将与你的其他代码在同一作用域内运行，这意味着它可以像你的Python文件中的其他代码一样**读取和操作变量**。

```python
x = 5

exec('print(x)')
```

`exec` allows you to run truly dynamic code at runtime.  You could, for example, download a Python file from the internet at  runtime, pass its content to `exec` and it will run it for you. (But please, never, ever do that.)

For the most part, you don't really need `exec` while writing your code. It's useful for implementing some really  dynamic behaviour (such as creating a dynamic class at runtime, like `collections.namedtuple` does), or to modify the code being read from a Python file (like in [zxpy](https://github.com/tusharsadhwani/zxpy/blob/3e4eb5e344601cc5a1b4e4f9f72ac3f30111cc93/zx.py#L304)).

But, that's not the main topic of discussion today. We must learn *how* `exec` does all of these fancy runtime things.

`exec` can not only take in a string and run it as code, it can also take in a **code object**.

Code objects are the "bytecode" version of Python programs, as discussed  before. They contain not only the exact instructions generated from your Python code, but it also stores things like the variables and the  constants used inside that piece of code.

Code objects are  generated from ASTs (abstract syntax trees), which are themselves  generated by a parser that runs on a string of code.

> `exec`允许你在运行时**运行真正的动态代码**。 例如，你可以在运行时从互联网上下载一个 Python 文件，把它的内容传给 `exec`，它就会为你运行。(但请永远不要这样做。)
>
> 在大多数情况下，你在写代码时并不真正需要`exec`。对于实现一些真正的动态行为(比如在运行时**创建一个动态类**，像`collections.namedtuple`那样)，或者修改从Python文件中读取的代码(像在[zxpy](https://github.com/tusharsadhwani/zxpy/blob/3e4eb5e344601cc5a1b4e4f9f72ac3f30111cc93/zx.py#L304)中)，它很有用。
>
> 但是，这不是今天讨论的主要话题。我们必须学习*如何*`exec`做所有这些花哨的运行时事情。
>
> `exec`不仅可以接收一个字符串并作为代码运行，还可以接收一个**代码对象**。
>
> 代码对象是 Python 程序的 **"字节码"版本**，正如前面所讨论的。它们不仅包含了从你的Python代码中生成的**精确指令**，而且还存储了像在那段代码中使用的**变量和常数**的东西。
>
> 代码对象是由AST (抽象语法树abstract syntax trees) 生成的，AST本身是由运行在一串代码上的解析器生成的。

Now, if you're still here after all that nonsense, let's try to learn  this by example instead. We'll first generate an AST from our code using the `ast` module:

> 现在，如果你说了这么多废话后还在这里，让我们试着通过实例来学习一下。我们首先使用`ast`模块从我们的代码中生成一个AST：

```python
import ast
code = '''
x = [1, 2]
print(x)
'''

tree = ast.parse(code)
print(ast.dump(tree, indent=2))

Module(
  body=[
    Assign(
      targets=[
        Name(id='x', ctx=Store())],
      value=List(
        elts=[
          Constant(value=1),
          Constant(value=2)],
        ctx=Load())),
    Expr(
      value=Call(
        func=Name(id='print', ctx=Load()),
        args=[
          Name(id='x', ctx=Load())],
        keywords=[]))],
  type_ignores=[])
```

It might seem a bit too much at first, but let me break it down.

The `AST` is taken as a python module (the same as a Python file in this case).

> 一开始可能看起来有点多，但让我把它分解一下。
>
> `AST`被当作一个Python模块（在这种情况下与Python文件相同）。

```python
>>> print(ast.dump(tree, indent=2))
Module(
  body=[
    ...
```

The module's body has two children (two statements):

- The first is an `Assign` statement...

> 该模块的主体有两个子级（两个语句）：
>
> - 第一个是 `Assign` 语句...
>

```python
Assign(
    ...
```

Which assigns to the target `x`...

```python
targets=[
      Name(id='x', ctx=Store())],
    ...
```

The value of a `list` with 2 constants `1` and `2`.

```python
 value=List(
      elts=[
        Constant(value=1),
        Constant(value=2)],
      ctx=Load())),
  ),
```

The second is an `Expr` statement, which in this case is a function call...

```python
Expr(
    value=Call(
      ...
```

Of the name `print`, with the value `x`.

```python
 func=Name(id='print', ctx=Load()),
      args=[
        Name(id='x', ctx=Load())],
```

So the `Assign` part is describing `x = [1, 2]` and the `Expr` is describing `print(x)`. Doesn't seem that bad now, right?

> 所以 `Assign` 部分描述的是 `x = [1, 2]`，`Expr` 描述的是 `print(x)`。现在看来没有那么糟糕，对吗？

> Extras: the Tokenizer
>
> There's actually one step that occurs before parsing the code into an AST: **Lexing**.
>
> This refers to converting the source code into tokens, based on Python's *grammar*. You can take a look at how Python tokenizes your files, you can use the `tokenize` module:
>
> > 实际上，在将代码解析成AST之前，还有一个步骤：**Lexing**。
> >
> > 这指的是根据Python的*语法*，**将源代码转换为标记**。你可以看一下Python是如何对文件进行标记的，你可以使用`tokenize`模块。
>
> ```python
> $ cat code.py
> x = [1, 2]
> print(x)
> 
> $ py -m tokenize code.py
> 0,0-0,0:            ENCODING       'utf-8'
> 1,0-1,1:            NAME           'x'
> 1,2-1,3:            OP             '='
> 1,4-1,5:            OP             '['
> 1,5-1,6:            NUMBER         '1'
> 1,6-1,7:            OP             ','
> 1,8-1,9:            NUMBER         '2'
> 1,9-1,10:           OP             ']'
> 1,10-1,11:          NEWLINE        '\n'
> 2,0-2,5:            NAME           'print'
> 2,5-2,6:            OP             '('
> 2,6-2,7:            NAME           'x'
> 2,7-2,8:            OP             ')'
> 2,8-2,9:            NEWLINE        '\n'
> 3,0-3,0:            ENDMARKER      '
> ```
>
> It has converted our file into its bare tokens, things like variable  names, brackets, strings and numbers. It also keeps track of the line  numbers and locations of each token, which helps in pointing at the  exact location of an error message, for example.
>
> This "token stream" is what's parsed into an AST.
>
> > 它已经将我们的文件转换为其仅有的标记，如**变量名、括号、字符串和数字**。它还记录了每个标记的**行号和位置**，这有助于指出错误信息的确切位置，比如说。
> >
> > 这个 "**标记流** "就是被解析成AST的东西。

So now we have an AST object. We can *compile* it into a code object using the `compile` builtin. Running `exec` on the code object will then run it just as before:

> 所以现在我们有了一个AST对象。我们可以使用`compile`内置程序将其*编译*成一个代码对象。在代码对象上运行`exec`，就会像以前一样运行它：

```python
>>> import ast
>>> code = '''
... x = [1, 2]
... print(x)
... '''
>>> tree = ast.parse(code)
>>> code_obj = compile(tree, 'myfile.py', 'exec')
>>> exec(code_obj)
[1, 2]
```

But now, we can look into what a code object looks like. Let's examine some of its properties:

> 但现在，我们可以研究一下**代码对象**是什么样子的。让我们研究一下它的**一些属性**：

```python
>>> code_obj.co_code
b'd\x00d\x01g\x02Z\x00e\x01e\x00\x83\x01\x01\x00d\x02S\x00'
>>> code_obj.co_filename
'myfile.py'
>>> code_obj.co_names
('x', 'print')
>>> code_obj.co_consts
(1, 2, None)
```

You can see that the variables `x` and `print` used in the code, as well as the constants `1` and `2`, plus a lot more information about our code file is available inside the code object. This has all the information needed to directly run in the Python virtual machine, in order to produce that output.

If you want to dive deep into what the bytecode means, the extras section below on the `dis` module will cover that.

> 你可以看到在代码中使用的变量`x`和`print`，以及常量`1`和`2`，还有很多关于我们的代码文件的信息都可以在**代码对象**中找到。这有**直接在Python虚拟机中运行**所需的所有信息，以便产生该输出。
>
> 如果你想**深入了解字节码**的含义，下面关于 `dis` 模块的**额外部分**将涵盖这个内容。

> Extras: the "dis" module
>
> The `dis` module in Python can be used to visualize the  contents of code objects in a human-understandable way, to help figure  out what Python is doing under the hood. It takes in the bytecode,  constant and variable information, and produces this:
>
> Python中的`dis`模块可以用来以人类可理解的方式**可视化**代码对象的内容，以帮助弄清Python在幕后做了什么。它**接收字节码、常量和变量**信息，并产生这个结果：
>
> ```python
> >>> import dis
> >>> dis.dis('''
> ... x = [1, 2]
> ... print(x)
> ... ''')
>   1           0 LOAD_CONST               0 (1)
>               2 LOAD_CONST               1 (2)
>               4 BUILD_LIST               2
>               6 STORE_NAME               0 (x)
> 
>   2           8 LOAD_NAME                1 (print)
>              10 LOAD_NAME                0 (x)
>              12 CALL_FUNCTION            1
>              14 POP_TOP
>              16 LOAD_CONST               2 (None)
>              18 RETURN_VALUE
> >>>
> ```
>
> It shows that:
>
> - Line 1 creates 4 bytecodes, to load 2 constants `1` and `2` onto the stack, build a list from the top `2` values on the stack, and store it into the variable `x`.
> - Line 2 creates 6 bytecodes, it loads `print` and `x` onto the stack, and calls the function on the stack with the `1` argument on top of it (Meaning, it calls `print` with argument `x`). Then it gets rid of the return value from the call by doing `POP_TOP` because we didn't use or store the return value from `print(x)`. The two lines at the end returns `None` from the end of the file's execution, which does nothing.
>
> > 这表明：
> >
> > - 第1行创建了4个字节码，将2个常量（数字常量）`1`和`2`加载到**堆栈**中，从堆栈中最上面的`2`值建立一个列表，并将其存储到变量`x`中。
> > - 第2行创建了6个字节码，它将`print`和`x`加载到**堆栈**中，并调用堆栈中`1`参数上面的函数（意思是，它用参数`x`调用`print`）。然后它通过做`POP_TOP`来摆脱调用的返回值，因为我们没有使用或存储`print(x)`的返回值。最后的两行从文件的**执行结束时**返回`None`，它没有做什么。
>
> Each of these bytecodes is 2 bytes long when stored as "opcodes" (the names that you are seeing, `LOAD_CONST` for example, are opcodes), that's why the numbers to the left of the  opcodes are 2 away from each other. It also shows that this entire code  is 20 bytes long. And indeed, if you do:
>
> > 当作为 "操作码 "存储时，每个字节码都有2个长度（你看到的名字，例如`LOAD_CONST`，就是**操作码**），这就是为什么操作码左边的数字是2的距离。这也表明，这整个代码有**20个字节长**。而事实上，如果你这样做：
>
> ```python
> >>> code_obj = compile('''
> ... x = [1, 2]
> ... print(x)
> ... ''', 'test', 'exec')
> >>> code_obj.co_code
> b'd\x00d\x01g\x02Z\x00e\x01e\x00\x83\x01\x01\x00d\x02S\x00'
> >>> len(code_obj.co_code)
> 20
> ```
>
> You can confirm that the bytecode generated is exactly 20 bytes.
>
> > 你可以确认生成的字节码正好是**20字节**。

`eval` is pretty similar to `exec`, except it only accepts expressions (not statements or a set of statements like `exec`), and unlike `exec`, it returns a value -- the result of said expression.

Here's an example:

> `eval`与`exec`非常相似，只是它只接受表达式（而不是像`exec`那样的语句或一组语句），而且与`exec`不同，它**返回一个值**--上述表达式的结果。
>
> 这里有一个例子：

```python
>>> result = eval('1 + 1')
>>> result
2
```

You can also go the long, detailed route with `eval`, you just need to tell `ast.parse` and `compile` that you're expecting to evaluate this code for its value, instead of running it like a Python file.

> 你也可以用`eval`走漫长而详细的路线，你只需要告诉`ast.parse`和`compile`你希望**运行计算**这段代码的值，而不是像Python文件一样运行它。

```python
>>> expr = ast.parse('1 + 1', mode='eval')
>>> code_obj = compile(expr, '<code>', 'eval')
>>> eval(code_obj)
2
```

### `globals` and `locals`: Where everything is stored

While the code objects produced store the logic as well as constants  defined within a piece of code, one thing that they don't (or even  can't) store, is the actual values of the variables being used.

There's a few reasons for this concerning how the language works, but the most obvious reason can be seen very simply:

> 虽然产生的代码对象存储了**逻辑**以及在一段代码中定义的**常数**，但有一件事它们并不（甚至不能）存储，那就是正在使用的**变量的实际值**。
>
> 关于语言的工作方式，有几个原因，但最明显的原因可以很简单地看到：

```python
def double(number):
    return number * 2
```

The code object of this function will store the constant `2`, as well as the variable name `number`, but it obviously cannot contain the actual value of `number`, as that isn't given to it until the function is actually run.

So where does that come from? The answer is that Python stores everything  inside dictionaries associated with each local scope. Which means that  every piece of code has its own defined "local scope" which is accessed  using `locals()` inside that code, that contains the values corresponding to each variable name.

Let's try to see that in action:

> 这个函数的代码对象将存储**常数**`2`，以及**变量名**`number`，但它显然不能包含`number`的**实际值**，因为在函数实际运行之前，它不会被赋予这个值。
>
> 那么它是从哪里来的呢？答案是，Python 把所有东西都存储在与**每个局部作用域相关的字典**里。这意味着每段代码都有自己定义的 "局部作用域"，可以在代码中使用 `locals()` 来访问，它包含了与每个变量名对应的值。
>
> 让我们试着看一下这个动作：

```python
>>> value = 5
>>> def double(number):
...     return number * 2
...
>>> double(value)
10
>>> locals()
{'__name__': '__main__', '__doc__': None, '__package__': None,
'__loader__': <class '_frozen_importlib.BuiltinImporter'>, '__spec__': None,
'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>,
'value': 5, 'double': <function double at 0x7f971d292af0>}
```

Take a look at the last line: not only is `value` stored inside the locals dictionary, the function `double` itself is stored there as well! So that's how Python stores its data.

`globals` is pretty similar, except that `globals` always points to the module scope (also known as global scope). So with something like this code:

> 看看最后一行：不仅是 `value` 存储在 locals 字典中，函数 `double` 本身也存储在那里! 所以这就是 Python **存储数据的方式**。
>
> `globals`也很类似，只是`globals`总是指向模块作用域 (也被称为全局作用域)。所以像这样的代码：

```python
magic_number = 42

def function():
    x = 10
    y = 20
    print(locals())
    print(globals())
```

`locals` would just contain `x` and `y`, while `globals` would contain `magic_number` and `function` itself.

> `locals`将只包含`x`和`y`，而`globals`将包含`magic_number`和`function`本身。

### `input` and `print`: The bread and butter

`input` and `print` are probably the first two functionalities that you learn about Python. And they seem pretty straightforward, don't they? `input` takes in a line of text, and `print` prints it out, simple as that. Right?

Well, `input` and `print` have a bit more functionality than what you might know about.

Here's the full method signature of `print`:

> `input`和`print`可能是你学习Python的**头两个功能**。它们看起来很简单，不是吗？`input`输入一行文本，`print`将其打印出来，就这么简单。对吗？
>
> 嗯，`input`和`print`的功能比你可能知道的要多一点。
>
> 下面是 "print "的完整方法标识。

```python
print(*objects, sep=' ', end='\n', file=sys.stdout, flush=False)
```

The `*objects` simply means that you can provide any number of positional arguments to `print`, and it will properly print them out, separated with spaces by default.

If you want the separator to be different, for eg. if you want each item to be printed on a different line, you can set the `sep` keyword accordingly, like `'\n'`:

> `*objects`简单表示你可以向`print`提供**任意数量的位置参数**，它将正确地打印出来，默认用**空格**字符串分隔。
>
> 如果你想让分隔符不同，例如，如果你想让每个项目打印在不同的行上，你可以相应地设置`sep`关键字，如`'\n'`：

```python
>>> print(1, 2, 3, 4)
1 2 3 4
>>> print(1, 2, 3, 4, sep='\n')
1
2
3
4
>>> print(1, 2, 3, 4, sep='\n\n')
1

2

3

4
>>>
```

There's also an `end` parameter, if you want a different  character for line ends, like, if you don't want a new line to be  printed at the end of each print, you can use `end=''`:

> 还有一个`end`参数，如果你想用不同的字符来表示**行尾**，比如，如果你不希望在每次打印结束时打印一个新行，你可以使用`end=' '`：

```python
>>> for i in range(10):
...     print(i)
0
1
2
3
4
5
6
7
8
9
>>> for i in range(10):
...     print(i, end='')
0123456789
```

Now there's two more parameters to `print`: `file` and `flush`.

`file` refers to the "file" that you are printing to. By default it points to `sys.stdout`, which is a special "file" wrapper, that prints to the console. But if you want `print` to write to a file instead, all you have to do is change the `file` parameter. Something like:

> 现在`print`还有两个参数：`file`和`flush`。
>
> `file`指的是你要打印的 "文件"。默认情况下，它指向`sys.stdout`，它是一个特殊的 "文件"包装器，可以打印到**控制台**。但是如果你想让`print`写到一个**文件**里，你只需要改变`file`参数。比如说

```python
with open('myfile.txt', 'w') as f:
    print('Hello!', file=f)
```

> Extras: using a context manager to make a print-writer
>
> Some languages have special objects that let you call `print` method on them, to write to a file by using the familiar "print"  interface. In Python, you can go a step beyond that: you can temporarily configure the `print` function to write to a file by default!
>
> This is done by re-assigning `sys.stdout`. If we swap out the file that `sys.stdout` is assigned to, then all `print` statements magically start printing to that file instead. How cool is that?
>
> Let's see with an example:
>
> > 一些语言有**特殊的对象**，可以让你在上面调用`print`方法，通过使用熟悉的 "print "接口写到一个文件。在Python中，你可以更进一步：你可以**临时配置**`print`函数，使其默认写到一个文件！这可以通过重新分配`sys.stdout`来实现。
> >
> > 这是通过重新分配`sys.stdout`来实现的。如果我们把`sys.stdout`分配给的文件换掉，那么所有的`print`语句就神奇地开始打印到该文件。这有多酷呢？
> >
> > 让我们通过一个例子来看看：
>
> ```python
> >>> import sys
> >>> print('a regular print statement')
> a regular print statement
> >>> file = open('myfile.txt', 'w')
> >>> sys.stdout = file
> >>> print('this will write to the file')  # Gets written to myfile.txt
> >>> file.close()
> ```
>
> But, there's a problem here. We can't go back to printing to console this way. And even if we store the original `stdout`, it would be pretty easy to mess up the state of the `sys` module by accident.
>
> For example:
>
> > 但是，这里有一个问题。我们不能用这种方式**回到打印到控制台**。而且，即使我们存储了原始的`stdout`，也很容易意外地弄乱`sys`模块的状态。
> >
> > 比如说：
>
> ```python
> >>> import sys
> >>> print('a regular print statement')
> a regular print statement
> >>> file = open('myfile.txt', 'w')
> >>> sys.stdout = file
> >>> file.close()
> >>> print('this will write to the file')
> Traceback (most recent call last):
>   File "<stdin>", line 2, in <module>
> ValueError: I/O operation on closed file.
> ```
>
> To avoid accidentally leaving the `sys` module in a broken state, we can use a **context manager**, to ensure that `sys.stdout` is restored when we are done.
>
> > 为了避免不小心让 `sys` 模块处于崩溃状态，我们可以使用一个**语境管理器**，以确保当我们完成工作后，`sys.stdout` 被恢复。
>
> ```python
> import sys
> from contextlib import contextmanager
> 
> @contextmanager
> def print_writer(file_path):
>     original_stdout = sys.stdout
> 
>     with open(file_path, 'w') as f:
>         sys.stdout = f
>         yield  # this is where everything inside the `with` statement happens
>         sys.stdout = original_stdout
> ```
>
> That's it! And here's how you would use it:
>
> ```python
> with print_writer('myfile.txt'):
>     print('Printing straight to the file!')
>     for i in range(5):
>         print(i)
> 
> print('and regular print still works!')
> ```
>
> Sending prints to files or IO objects is a common enough use-case that `contextlib` has a pre-defined function for it, called `redirect_stdout`:
>
> > 向文件或IO对象**发送打印数据**是一个很常见的情况，`contextlib`有一个预定义的函数，叫做`redirect_stdout`：
>
> ```python
> from contextlib import redirect_stdout
> 
> with open('this.txt', 'w') as file:
>     with redirect_stdout(file):
>         import this
> 
> with open('this.txt') as file:
>     print(file.read())
> 
> # Output:
> # The Zen of Python, by Tim Peters
> # ...
> ```

`flush` is a boolean flag to the `print` function. All it does is tell `print` to write the text immediately to the console/file instead of putting it in a buffer. This usually doesn't make much of a difference, but if  you're printing a very large string to a console, you might want to set  it to `True` to avoid lag in showing the output to the user.

Now I'm sure many of you are interested in what secrets the `input` function hides, but there's none. `input` simply takes in a string to show as the prompt. Yeah, bummer, I know.

> `flush`是`print`函数的一个**布尔**标志。它的作用是告诉`print`立即把文本写到控制台/文件中，而不是放在缓冲区中。这通常没有什么区别，但如果你要打印一个非常大的字符串到控制台，你可能想把它设置为 `True`，以避免在向用户显示输出时出现延迟。
>
> 现在我相信你们中的许多人对`input`函数隐藏了什么秘密感兴趣，但其实没有什么秘密。`input`只是接收了一个**字符串**作为提示。是的，很遗憾，我知道。

### `str`, `bytes`, `int`, `bool`, `float` and `complex`: The five primitives

Python has exactly 6 primitive data types (well, actually just 5, but we'll get to that). 4 of these are numerical in nature, and the other 2 are text-based. Let's talk about the text-based first, because that's  going to be much simpler.

`str` is one of the most familiar data types in Python. Taking user input using the `input` method gives you a string, and every other data type in Python can be  converted into a string. This is necessary because all computer  Input/Output is in text-form, be it user I/O or file I/O, which is  probably why strings are everywhere.

`bytes` on the other hand, are *actually* the basis of all I/O in computing. If you know about computers, you  would probably know that all data is stored and handled as bits and  bytes -- and that's how terminals really work as well.

If you want to take a peek at the bytes underneath the `input` and `print` calls: you need to take a look at the I/O buffers in the `sys` module: `sys.stdout.buffer` and `sys.stdin.buffer`:

> Python 有整整 6 种原始数据类型 (好吧，实际上只有 5 种，但我们会讨论这个问题)。其中 4 个是**数字性质**的，另外两个是**基于文本**的。让我们先谈谈基于文本的数据，因为这将会更简单。
>
> `str`是Python中最熟悉的数据类型之一。使用`input`方法接受用户的输入会得到一个字符串，而Python中的每一个**其他数据类型都可以转换成字符串**。这是必要的，因为所有的计算机输入/输出都是**文本形式**的，无论是用户输入/输出还是文件输入/输出，这可能就是为什么字符串无处不在。
>
> 另一方面，`bytes`实际上是计算中所有I/O的**基础**。如果你了解计算机，你可能会知道，所有的数据都是**以比特和字节的形式存储和处理**的--这也是终端的真正工作方式。
>
> 如果你想看看`input`和`print`调用下面的字节：你需要看一下`sys`模块中的I/O缓冲区。`sys.stdout.buffer`和`sys.stdin.buffer`：

```python
>>> import sys
>>> print('Hello!')
Hello!
>>> 'Hello!\n'.encode()  # Produces bytes
b'Hello!\n'
>>> char_count = sys.stdout.buffer.write('Hello!\n'.encode())
Hello!
>>> char_count  # write() returns the number of bytes written to console
7
```

The buffer objects take in `bytes`, write those directly to the output buffer, and return the number of bytes returned.

To prove that everything is just bytes underneath, let's look at another example that prints an emoji using its bytes:

> **缓冲区对象**接收 "bytes"，把这些直接写到输出缓冲区，并返回返回的字节数。
>
> 为了证明内层的一切都只是字节，让我们看看另一个例子，用它的字节来打印一个表情符号：
>

```python
>>> import sys
>>> '🐍'.encode()
b'\xf0\x9f\x90\x8d'   # utf-8 encoded string of the snake emoji
>>> _ = sys.stdout.buffer.write(b'\xf0\x9f\x90\x8d')
🐍
```

`int` is another widely-used, fundamental primitive data type. It's also the lowest common denominator of 2 other data types: , `float` and `complex`. `complex` is a supertype of `float`, which, in turn, is a supertype of `int`.

What this means is that all `int`s are valid as a `float` as well as a `complex`, but not the other way around. Similarly, all `float`s are also valid as a `complex`.

> `int`是另一个广泛使用的**基本原始数据类型**。它也是其他两种数据类型的**最低共同点**。`float`和`complex`。`complex`是 `float`的一个**超类型**，而 `float`又是 `int`的一个超类型。
>
> 这意味着所有的 `int`作为 `float` 和 `complex` 都是有效的，但反之则无效。同样地，所有的`float`也可以作为`complex`使用。

> If you don't know, `complex` is the implementation for "complex numbers" in Python. They're a really common tool in mathematics.
>
> > 如果你不知道，`complex`是Python中 "复数"的实现。它们是**数学中一个非常常见的工具**。

Let's take a look at them:

```python
>>> x = 5
>>> y = 5.0
>>> z = 5.0+0.0j
>>> type(x), type(y), type(z)
(<class 'int'>, <class 'float'>, <class 'complex'>)
>>> x == y == z  # All the same value
True
>>> y
5.0
>>> float(x)    # float(x) produces the same result as y
5.0
>>> z
(5+0j)
>>> complex(x)  # complex(x) produces the same result as z
(5+0j)
```

Now, I mentioned for a moment that there's actually only 5 primitive data types in Python, not 6. That is because, `bool` is actually not a primitive data type -- it's actually a subclass of `int`!

You can check it yourself, by looking into the `mro` property of these classes.

`mro` stands for "method resolution order". It defines the order in which the methods called on a class are looked for. Essentially, the method calls are first looked for in the class itself, and if it's not present  there, it's searched in its parent class, and then its parent, all the  way to the top: `object`. Everything in Python inherits from `object`. Yes, pretty much everything in Python is an object.

Take a look:

> 现在，我提到，Python中实际上只有5种原始数据类型，而不是6种。这是因为，`bool`实际上不是一个原始数据类型 -- 它实际上是`int`的一个**子类**!
>
> 你可以通过查看这些类的 `mro` 属性，自己检查一下。
>
> `mro`代表了 "方法解析顺序"。它定义了在一个**类上调用的方法被寻找的顺序**。基本上，方法调用首先在类本身中寻找，如果不在那里，就在其父类中寻找，然后是其父类，一直到顶部。`object`。Python 中的一切都继承自 `object`。是的，**Python 中几乎所有的东西都是一个对象**。
>
> 看看吧：

```python
>>> int.mro()
[<class 'int'>, <class 'object'>]
>>> float.mro()
[<class 'float'>, <class 'object'>]
>>> complex.mro()
[<class 'complex'>, <class 'object'>]
>>> str.mro()
[<class 'str'>, <class 'object'>]
>>> bool.mro()
[<class 'bool'>, <class 'int'>, <class 'object'>]  # Look!
```

You can see from their "ancestry", that all the other data types are not "sub-classes" of anything (except for `object`, which will always be there). Except `bool`, which inherits from `int`.

Now at this point, you might be wondering "WHY? Why does `bool` subclass `int`?" And the answer is a bit anti-climatic. It's mostly because of  compatibility reasons. Historically, logical true/false operations in  Python simply used `0` for false and `1` for true. In Python version 2.2, the boolean values `True` and `False` were added to Python, and they were simply wrappers around these  integer values. The fact has stayed the same till date. That's all.

But, it also means that, for better or for worse, you can pass a `bool` wherever an `int` is expected:

> 你可以从它们的 "起祖"中看到，所有其他的数据类型都不是任何东西的 "子类"（除了`object`，它将永远存在）。除了`bool`，它**继承自**`int`。
>
> 现在，你可能想知道 "为什么？ 为什么`bool`会子类化`int`？" 而答案是有点反常的。这主要是由于**兼容性**的原因。历史上，Python中的逻辑真/假操作只是用`0`表示假，`1`表示真。在Python 2.2版本中，布尔值`True`和`False`被添加到Python中，它们只是**这些整数值的包装**。这个事实直到现在都没有改变。这就是全部。
>
> 但是，这也意味着，不管是好是坏，你都可以在期望使用 `int` 的地方传递一个 `bool`。

```python
>>> import json
>>> data = {'a': 1, 'b': {'c': 2}}
>>> print(json.dumps(data))
{"a": 1, "b": {"c": 2}}
>>> print(json.dumps(data, indent=4))
{
    "a": 1,
    "b": {
        "c": 2
    }
}
>>> print(json.dumps(data, indent=True))    # here True equals 1
{
 "a": 1,
 "b": {
  "c": 2
 }
}
```

`indent=True` here is treated as `indent=1`, so it works, but I'm pretty sure nobody would intend that to mean an indent of 1 space. Welp.

> `indent=True` 在这里被视为 `indent=1`，所以它是有效的，但我敢肯定，没有人会认为这意味着缩进1个空格。好吧。

### `object`: The base

`object` is the base class of the entire class hierarchy. Everyone inherits from `object`.

The `object` class defines some of the most fundamental properties of objects in  Python. Functionalities like being able to hash an object through `hash()`, being able to set attributes and get their value, being able to convert an object into a string representation, and many more.

It does all of this through its pre-defined "magic methods":

> `object`是**整个类层次结构的基类**。每个人都继承于`object`。
>
> `object`类定义了Python中对象的一些**最基本的属性**。诸如能够通过`hash()`散列一个对象，能够设置属性并获得其值，能够将一个对象转换为字符串表示，以及更多的功能。
>
> 它通过预定义的 "magic methods"完成所有这些工作。

```python
dir(object)
['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__',
'__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__',
'__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__',
'__setattr__', '__sizeof__', '__str__', '__subclasshook__']
```

Accessing an attribute with `obj.x` calls the `__getattr__` method underneath. Similarly setting a new attribute and deleting an attribute calls `__setattr__` and `__delattr__` respectively. The object's hash is generated by the pre-defined `__hash__` method, and the string representation of objects comes from `__repr__`.

> 用`obj.x`访问一个属性时，调用下面的`__getattr__`方法。类似地，设置一个新的属性和删除一个属性分别调用`__setattr__`和`__delattr__`。对象的哈希值由预定义的`__hash__`方法生成，而对象的字符串表示则来自`__repr__`。

```python
>>> object()  # This creates an object with no properties
<object object at 0x7f47aecaf210>  # defined in __repr__()
>>> class dummy(object):
...     pass
>>> x = dummy()
>>> x
<__main__.dummy object at 0x7f47aec510a0>  # functionality inherited from object
>>> hash(object())
8746615746334
>>> hash(x)
8746615722250
>>> x.__hash__()  # is the same as hash(x)
8746615722250
```

> There's actually a lot more to speak about magic methods in Python,  as they form the backbone of the object-oriented, duck-typed nature of  Python. But, that's a story for another blog.
>
> Stay tuned if you're interested 😉
>
> > 关于Python中的魔法方法，其实还有很多要讲的，因为它们构成了Python面向对象、鸭子类型的主干。但是，那是另一篇博客的故事。
> >
> > 如果你感兴趣，请继续关注😉。

### `type`: The class factory

If `object` is the father of all objects, `type` is father of all "classes". As in, while all objects inherit from `object`, all classes inherit from `type`.

`type` is the builtin that can be used to dynamically create new classes. Well, it actually has two uses:

> 如果`object`是所有对象的父亲，`type`是所有 "类"的父亲。正如所有的对象都继承于`object`，所有的类都继承于`type`。
>
> `type`是一个可以用来**动态创建新类**的内置程序。嗯，它实际上有两个用途：

- If given a single parameter, it returns the "type" of that parameter, i.e. the class used to make that object:

```python
>>> x = 5
>>> type(x)
<class 'int'>
>>> type(x) is int
True
>>> type(x)(42.0)  # Same as int(42.0)
42
```

- If given three parameters, it creates a new class. The three parameters are `name`, `bases`, and `dict`.

  - `name` defines the name of the class

  - `bases` defines the base classes, i.e. superclasses

  - `dict` defines all class attributes and methods.

So this class definition:

> - 如果给出三个参数，它就会创建一个新的类。这三个参数是`name`, `bases`, 和`dict`。
>
>   - `name`定义了**类的名称**。
>
>   - `bases`定义了**基类**，即超类
>
>   - `dict`定义了所有的**类属性和方法**。
>
> 所以这个类的定义：

```python
class MyClass(MySuperClass):
    def x(self):
        print('x')
```

Is identical to this class definition:

```python
def x_function(self):
    print('x')

MyClass = type('MyClass', (MySuperClass,), {'x': x_function})
```

This can be one way to implement the `collections.namedtuple` class, for example, which takes in a class name and a tuple of attributes.

> 这可以是实现`collections.namedtuple`类的一种方式，例如，它接收一个类名和一个属性的元组。

### `hash` and `id`: The equality fundamentals

The builtin functions `hash` and `id` make up the backbone of object equality in Python.

Python objects by default aren't comparable, unless they are identical. If you try to create two `object()` items and check if they're equal...

> 内建函数`hash`和`id`构成了Python中对象相等性的骨干。
>
> 默认情况下，Python 对象是不能比较的，除非它们是相同的。如果你试图创建两个`object()`项并检查它们是否相等......

```python
>>> x = object()
>>> y = object()
>>> x == x
True
>>> y == y
True
>>> x == y  # Comparing two objects
False
```

The result will always be `False`. This comes from the fact that `object`s compare themselves by identity: They are only equal to themselves, nothing else.

> 其结果总是 `False`。这来自于 `object`s 通过身份比较自己的事实。它们只与自己相等，没有其他。
>

> Extras: Sentinels
>
> For this reason, `object` instances are also sometimes  called a "sentinel", because they can be used to check for a value  exactly, that can't be replicated.
>
> A nice use-case of sentinel values comes in a case where you need to  provide a default value to a function where every possible value is a  valid input. A really silly example would be this behaviour:
>
> 由于这个原因，"对象"实例有时也被称为 "哨兵"，因为它们可以被用来精确地检查一个不能被复制的值。
>
> 哨兵值的一个很好的用例是，你需要为一个函数提供一个默认值，而每个可能的值都是一个有效的输入。一个非常愚蠢的例子就是这种行为：
>
> ```python
> >>> what_was_passed(42)
> You passed a 42.
> >>> what_was_passed('abc')
> You passed a 'abc'.
> >>> what_was_passed()
> Nothing was passed.
> ```
>
> And at first glance, being able to write this code out would be pretty simple:
>
> ```python
> def what_was_passed(value=None):
>     if value is None:
>         print('Nothing was passed.')
>     else:
>         print(f'You passed a {value!r}.')
> ```
>
> But, this doesn't work. What about this:
>
> ```python
> >>> what_was_passed(None)
> Nothing was passed.
> ```
>
> Uh oh. We can't explicitly pass a `None` to the function, because that's the default value. We can't really use any other literal or even `...` Ellipsis, because those won't be able to be passed then.
>
> This is where a sentinel comes in:
>
> ```python
> __my_sentinel = object()
> 
> def what_was_passed(value=__my_sentinel):
>     if value is __my_sentinel:
>         print('Nothing was passed.')
>     else:
>         print(f'You passed a {value!r}.')
> ```
>
> And now, this will work for every possible value passed to it.
>
> ```python
> >>> what_was_passed(42)
> You passed a 42.
> >>> what_was_passed('abc')
> You passed a 'abc'.
> >>> what_was_passed(None)
> You passed a None.
> >>> what_was_passed(object())
> You passed a <object object at 0x7fdf02f3f220>.
> >>> what_was_passed()
> Nothing was passed.
> ```

To understand why objects only compare to themselves, we will have to understand the `is` keyword.

Python's `is` operator is used to check if two values reference the same exact object in memory. Think of Python objects like boxes floating around in space, and variables, array indexes, and so on being named arrows pointing to  these objects.

Let's take a quick example:

> 为了理解为什么**对象只和自己比较**，我们必须理解`is`关键字。
>
> Python的`is`运算符用来检查**两个值是否引用了内存中相同的确切对象**。想想看，Python 对象就像漂浮在空间中的盒子，而变量、数组索引等等是指向这些对象的**命名箭头**。
>
> 让我们举个简单的例子。

```python
>>> x = object()
>>> y = object()
>>> z = y
>>> x is y
False
>>> y is z
True
```

In the code above, there are two separate objects, and three labels `x`, `y` and `z` pointing to these two objects: `x` pointing to the first one, and `y` and `z` both pointing to the other one.

> 在上面的代码中，有两个独立的对象，有三个标签`x`、`y`和`z`指向这两个对象。`x`指向第一个对象，`y`和`z`都指向另一个对象。

```python
del x
```

This deletes the arrow `x`. The objects themselves aren't  affected by assignment, or deletion, only the arrows are. But now that  there are no arrows pointing to the first object, it is meaningless to  keep it alive. So Python's "garbage collector" gets rid of it. Now we  are left with a single `object`.

> 这就删除了箭头`x`。对象本身不受赋值或删除的影响，只有箭头受到影响。但是现在已经没有指向第一个对象的箭头了，让它继续存在是没有意义的。所以 Python 的 "垃圾收集器"把它处理掉了。现在我们只剩下一个 `object`。
>

```python
y = 5
```

Now `y` arrow has been changed to point to an integer object `5` instead. `z` still points to the second `object` though, so it's still alive.

> 现在`y`箭头已经改成指向一个整数对象`5`。`z`仍然指向第二个`对象`，所以它仍然存在。
>

```python
z = y * 2
```

Now z points to yet another new object `10`, which is stored somewhere in memory. Now the second `object` also has nothing pointing to it, so that is subsequently garbage collected.

> 现在z指向另一个新的对象`10`，它被存储在内存的某个地方。现在第二个`object`也没有任何东西指向它，所以它随后被垃圾回收。

To be able to verify all of this, we can use the `id` builtin function. `id` spells out a number that uniquely identifies the object during its  lifetime. In CPython that’s the exact memory location of that object,  but this is an implementation detail and other interpreters may choose a different representation.

> 为了能够验证这一切，我们可以使用`id`内置函数。`id`拼出了一个数字，在**对象的生命周期中唯一的标识**。在CPython中，这是该对象的确切内存位置，但这是一个实现细节，其他解释器可能会选择不同的表示。

```python
>>> x = object()
>>> y = object()
>>> z = y
>>> id(x)
139737240793600
>>> id(y)
139737240793616
>>> id(z)
139737240793616  # Notice the numbers!
>>> x is y
False
>>> id(x) == id(y)
False
>>> y is z
True
>>> id(y) == id(z)
True
```

Same object, same `id`. Different objects, different `id`. Simple as that.

> Extra: Small Integer Cache & String Interning
>
> 小整数缓存和字符串内部化
>
> First, some intriguing yet confusing code.
>
> > 首先，一些耐人寻味而又令人困惑的代码。
>
> ```python
> >>> x = 1
> >>> id(x)
> 136556405979440
> >>> y = 1
> >>> id(y)
> 136556405979440 # same int object?
> 
> >>> x = 257
> >>> id(x)
> 136556404964368
> >>> y = 257
> >>> id(y)
> 136556404964144 # but different int object now???
> 
> >>> x = "hello"
> >>> id(x)
> 136556404561904
> >>> y = "hello"
> >>> id(y)
> 136556404561904 # same str object?
> ```
>
> Integers and strings are objects that are used in almost any program, and in many cases there are copies of the same integer value or the  same string content. To save the time and memory of creating a whole new object when an exact same one is already there, CPython implements two  common techniques used in many other languages: Small Integer Cache  & String Interning.
>
> Although they have different names, the underlying idea is the same:  make objects immutable and reuse them across different references  (arrows). [Small Integer Cache](https://docs.python.org/3.8/c-api/long.html#c.PyLong_FromLong) makes integers in the range of [-5,256] reuse the same object for the same value. [String Interning](http://python-reference.readthedocs.io/en/latest/docs/functions/intern.html) points references to strings having the same content to the same object.
>
> This is just a simplified explanation, and you should read more if  you care about the memory consumption of your Python program. Hopefully  the code example makes sense to you now.
>
> > **整数**和**字符串**是几乎所有程序中都会用到的对象，在很多情况下，会有相同的整数值或相同的字符串内容的副本。为了节省在一个完全相同的对象已经存在的情况下创建一个全新对象的时间和内存，CPython实现了许多其他语言中常用的两种技术。**小整数缓存**和字符串内化。
> >
> > 虽然它们有不同的名字，但其基本思想是相同的：使对象不可改变，并在不同的引用中**复用**它们（箭头）。[小整数缓存](https://docs.python.org/3.8/c-api/long.html#c.PyLong_FromLong)使[**-5,256**]范围内的整数重复使用同一对象的相同值。[String Interning](http://python-reference.readthedocs.io/en/latest/docs/functions/intern.html)将具有**相同内容的字符串**的引用指向同一个对象。
> >
> > 这只是一个简化的解释，如果你关心你的Python程序的内存消耗，你应该阅读更多。希望这个代码例子现在对你有意义。

With `object`s, `==` and `is` behaves the same way:

> 对于 `object`，`==`和 `is` 的行为方式相同：

```python
>>> x = object()
>>> y = object()
>>> z = y
>>> x is y
False
>>> x == y
False
>>> y is z
True
>>> y == z
True
```

This is because `object`'s behaviour for `==` is defined to compare the `id`. Something like this:

> 这是因为`object`对`==`的行为被定义为比较`id`。就像这样：

```python
class object:
    def __eq__(self, other):
        return self is other
```

The actual implementation of `object` is written in C.

> Unlike `==`, there's no way to override the behavior of the `is` operator.
>
> > 与`==`不同，没有办法覆盖`is`操作符的行为。

Container types, on the other hand, are equal if they can be replaced  with each other. Good examples would be lists which have the same items  at the same indices, or sets containing the exact same values.

> 另一方面，如果容器类型可以相互替换，那么它们就是相等的。很好的例子是在**相同索引处有相同项目的列表**，或者包含**完全相同的值的集合**。

```python
>>> x = [1, 2, 3]
>>> y = [1, 2, 3]
>>> x is y
False       # Different objects,
>>> x == y
True        # Yet, equal.
```

These can be defined in this way:

```python
class list:
    def __eq__(self, other):
        if len(self) != len(other):
            return False
        
        return all(x == y for x, y in zip(self, other))
    
    # Cann also be writtern as:
    return all(self[i] == other[i] for i in range(len(self)))
```

> We haven't looked at `all` or `zip` yet, but all this does is make sure all of the given list indices are equal.
>
> > 我们还没有看过`all`或`zip`，但这只是确保所有给定的列表索引都是相等的。

Similarly, sets are unordered so even their location doesn't matter, only their "presence":

> 同样地，集合是**无序的**，所以即使它们的位置也不重要，只有它们的 "**存在**"。

```python
class set:
    def __eq__(self, other):
        if len(self) != len(other):
            return False
        
        return all(item in other for item in self)
```

Now, related to the idea of "equivalence", Python has the idea of **hashes**. A "hash" of any piece of data refers to a pre-computed value that looks pretty much random, but it can be used to identify that piece of data  (to some extent).

Hashes have two specific properties:

- The same piece of data will always have the same hash value.
- Changing the data even very slightly, returns in a drastically different hash.

What this means is that if two values have the same hash, it's very *likely* that they have the same value as well.

Comparing hashes is a really fast way to check for "presence". This is what  dictionaries and sets use to find values inside them pretty much  instantly:

> 现在，与 "相等"的概念相关，Python有**哈希**的概念。任何数据的 "哈希 "指的是一个**预先计算**的值，它看起来非常随机，但它可以用来**识别**该数据（在某种程度上）。
>
> 哈希值有两个特定的属性：
>
> - 同一块数据将永远有**相同的哈希值**。
> - 即使稍微改变一下数据，也会得到一个截然不同的哈希值。
>
> 这意味着，如果两个值有相同的哈希值，那么它们**很有可能**也有相同的值。
>
> 比较哈希值是检查 "存在 "的一个非常快速的方法。这也是字典和集合用来立即找到它们里面的值的方法：

```python
>>> import timeit
>>> timeit.timeit('999 in l', setup='l = list(range(1000))')
12.224023487000522   # 12 seconds to run a million times
>>> timeit.timeit('999 in s', setup='s = set(range(1000))')
0.06099735599855194  # 0.06 seconds for the same thing
```

Notice that the set solution is running hunderds of times faster than  the list solution! This is because they use the hash values as their  replacement for "indices", and if a value *at the same hash* is  already stored in the set/dictionary, Python can quickly check if it's  the same item or not. This process makes checking for presence pretty  much instant.

> 请注意，集合解决方案的运行速度比列表方案快了好几十倍！这是因为它们使用**哈希值**来替代 "索引"。这是因为他们使用哈希值作为 "索引 "的替代品，如果一个*相同的哈希值*已经存储在集合/字典中，Python 可以快速检查它是否是同一个项目。这个过程使得检查是否存在几乎是即时的。

> Extras: hash factoids
>
> Another little-known fact about hashes is that in Python, all numeric values that compare equal have the same hash:
>
> > 关于哈希值的另一个鲜为人知的事实是，在Python中，所有**比较相等的数字值都有相同的哈希值**。
>
> ```python
> >>> hash(42) == hash(42.0) == hash(42+0j)
> True
> ```
>
> Another factoid is that immutable container objects such as strings  (strings are a sequence of strings), tuples and frozensets, generate  their hash by combining the hashes of their items. This allows you to  create custom hash functions for your classes simply by composing the `hash` function:
>
> > 另一个事实是，不可变的容器对象，如字符串（**字符串是一个字符串序列**）、元组和frozensets，通过**组合其项目的哈希值来生成其哈希值**。这允许你为你的类创建**自定义的哈希函数**，只需组合`hash`函数即可。
>
> ```python
> class Car:
>     def __init__(self, color, wheels=4):
>         self.color = color
>         self.wheels = wheels
>         
>     def __hash__(self):
>         return hash((self.color, self.wheels))
> ```

### `dir` and `vars`: Everything is a dictionary

Have you ever wondered how Python stores objects, their variables,  their methods and such? We know that all objects have their own  properties and methods attached to them, but how exactly does Python  keep track of them?

The simple answer is that everything is stored inside dictionaries. And the `vars` method exposes the variables stored inside objects and classes.

> 你有没有想过，Python 是如何存储**对象**、它们的**变量**、它们的**方法**等等的？我们知道所有的对象都有自己的**属性**和方法，但是Python究竟是如何**跟踪它们**的？
>
> 简单的答案是，所有的东西都**存储在字典里面**。而`vars`方法揭示了存储在对象和类里面的变量。

```python
class C:
    some_constant = 42
    def __init__(self, x, y):
        self.x = x
        self.y = y
    def some_method(self):
        pass
    
>>> c = C(x=3, y=5)
>>> vars(c)
{'x': 3, 'y': 5}
>>> vars(C)
mappingproxy(
  {'__module__': '__main__', 'some_constant': 42,
  '__init__': <function C.__init__ at 0x7fd27fc66d30>,
  'some_method': <function C.some_method at 0x7fd27f350ca0>,
  '__dict__': <attribute '__dict__' of 'C' objects>,
  '__weakref__': <attribute '__weakref__' of 'C' objects>,
  '__doc__': None
})
```

As you can see, the attributes `x` and `y` related to the object `c` are stored in its own dictionary, and the methods (`some_function` and `__init__`) are actually stored as functions in the class's dictionary. Which makes sense, as the code of the function itself doesn't change for every  object, only the variables passed to it change.

This can be demonstrated with the fact that `c.method(x)` is the same as `C.method(c, x)`:

> 正如你所看到的，与对象`c`相关的属性`x`和`y`被存储在它自己的字典中，而方法（`some_function`和`__init__`）实际上是**作为函数存储在类的字典中**。这是有道理的，因为对于每个对象来说，函数本身的代码并没有改变，只是传递给它的变量改变了。
>
> 这可以用`c.method(x)`与`C.method(c, x)`相同的事实来证明：

```python
class C:
    def function(self, x):
        print(f'self={self}, x={x}')
        
>>> c = C()
>>> C.function(c, 5)
self=<__main__.C object at 0x7f90762461f0>, x=5
>>> c.function(5)
self=<__main__.C object at 0x7f90762461f0>, x=5
```

It shows that a function defined inside a class really is just a function, with `self` being just an object that is passed as the first argument. The object syntax `c.method(x)` is just a cleaner way to write `C.method(c, x)`.

Now here's a slightly different question. If `vars` shows all methods inside a class, then why does this work?

> 它表明在类中定义的函数真的**只是一个函数**，`self`只是一个**作为第一个参数传递**的对象。对象语法`c.method(x)`只是一种**更简洁的写法**的`C.method(c, x)`。
>
> 现在有一个稍微不同的问题。如果`vars`显示了一个类中的所有方法，那么为什么会这样呢？
>

```python
class C:
    def function(self, x): pass

>>> vars(C)
mappingproxy({
  '__module__': '__main__',
  'function': <function C.function at 0x7f607ddedb80>,
  '__dict__': <attribute '__dict__' of 'C' objects>,
  '__weakref__': <attribute '__weakref__' of 'C' objects>,
  '__doc__': None
})
>>> c = C()
>>> vars(c)
{}
>>> c.__class__
<class '__main__.C'>
```

🤔 `__class__` is defined in neither `c`'s dict, nor in `C`... then where is it coming from?

If you want a definitive answer of which properties can be accessed on an object, you can use `dir`:

>  `__class__`既没有在`c`的dict中定义，也没有在`C`中定义......那么它是从哪里来的？
>
> 如果你想知道**哪些属性可以在一个对象上被访问**，你可以使用`dir`来确定答案。

```python
>>> dir(c)
['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__',
'__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__',
'__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__',
'__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__',
'__subclasshook__', '__weakref__', 'function']
```

So where are the rest of the properties coming from? Well, the story  is slightly more complicated, for one simple reason: Python supports  inheritance.

All objects in python inherit by default from the `object` class, and indeed, `__class__` is defined on `object`:

> 那么，**其余的属性**是从哪里来的？嗯，这个故事稍微复杂一些，原因很简单。Python支持**继承**。
>
> python中的所有对象都默认继承自`object`类，事实上，`__class__`是定义在`object`上的。

```python
>>> '__class__' in vars(object)
True
>>> vars(object).keys()
dict_keys(['__repr__', '__hash__', '__str__', '__getattribute__', '__setattr__',
'__delattr__', '__lt__', '__le__', '__eq__', '__ne__', '__gt__', '__ge__',
'__init__', '__new__', '__reduce_ex__', '__reduce__', '__subclasshook__',
'__init_subclass__', '__format__', '__sizeof__', '__dir__', '__class__', '__doc__'])
```

And that does cover everything that we see in the output of `dir(c)`.

Now that I've mentioned inheritence, I think I should also elaborate how  the "method resolution order" works. MRO for short, this is the list of  classes that an object inherits properties and methods from. Here's a  quick example:

> 而这确实涵盖了我们在`dir(c)`的输出中看到的一切。
>
> 既然我已经提到了**继承性**，我想我也应该阐述一下 "**方法解析顺序** "是如何工作的。简称MRO，这是一个对象继承的属性和方法的类的列表。这里有一个简单的例子：

```python
class A:
    def __init__(self):
        self.x = 'x'
        self.y = 'y'
        
class B(A):
    def __init__(self):
        self.z = 'z'
        
>>> a = A()
>>> b = B()
>>> B.mro()
[<class '__main__.B'>, <class '__main__.A'>, <class 'object'>]
>>> dir(b)
['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__',
'__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__',
'__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__',
'__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__',
'__subclasshook__', '__weakref__', 'x', 'y', 'z']
>>> set(dir(b)) - set(dir(a))  # all values in dir(b) that are not in dir(a)
{'z'}
>>> vars(b).keys()
dict_keys(['z'])
>>> set(dir(a)) - set(dir(object))
{'x', 'y'}
>>> vars(a).keys()
dict_keys(['x', 'y'])
```

So every level of inheritence adds the newer methods into the `dir` list, and `dir` on a subclass shows all methods found in its method resolution order.  And that's how Python suggests method completion in the REPL:

> 所以**每一级的继承**都会把较新的方法加入到`dir`列表中，在子类上的`dir`显示所有在其**方法解析顺序中找到的方法**。 这就是Python在REPL中提示方法完成的方式：

```python
class A:
    x = 'x'
    
class B(A):
    y = 'y'
    
>>> b = B()
>>> b.    # Press <tab> twice here
b.x  b.y  # autocompletion!
```

> Extras: slots?
>
> `__slots__` are interesting.
>
> Here's one weird/interesting behaviour that Python has:
>
> > `__slots__`很有趣。
> >
> > 这里有一个Python的奇怪/有趣的行为：
>
> ```python
> >>> x = object()
> >>> x.foo = 5
> AttributeError: 'object' object has no attribute 'foo'
> >>> class C:
> ...     pass
> ...
> >>> c = C()
> >>> c.foo = 5
> >>> # works?
> ```
>
> So, for some reason you can't assign arbitrary variables to `object`, but you can to an object of a class that you yourself created. Why could that be? Is it specific to `object`?
>
> > 所以，由于某些原因，你不能给`object`赋值任意的变量，但你可以给你自己创建的类的对象赋值。为什么会这样？这是对 `object` 的特殊要求吗？
>
> ```python
> >>> x = list()
> >>> x.foo = 5
> AttributeError: 'list' object has no attribute 'foo'
> ```
>
> Nope. So what's going on?
>
> Well, This is where slots come in. Firstly, let me replicate the behaviour shown by `list` and `object` in my own class:
>
> > 不。那么发生了什么事？
> >
> > 嗯，这就是**槽**的作用。首先，让我在自己的类中复制`list`和`object`所显示的行为：
>
> ```python
> >>> class C:
> ...     __slots__ = ()
> ...
> >>> c = C()
> >>> c.foo = 5
> AttributeError: 'C' object has no attribute 'foo'
> ```
>
> Now here's the long explanation:
>
> Python actually has two ways of storing data inside objects: as a  dictionary (like most cases), and as a "struct". Structs are a C  language data type, which can essentially be thought of as tuples from  Python. Dictionaries use more memory, because they can be expanded as  much as you like and rely on extra space for their reliability in  quickly accessing data, that's just how dictionaries are. Structs on the other hand, have a fixed size, and cannot be expanded, but they take  the least amount of memory possible as they pack those values one after  the other without any wasted space.
>
> These two ways of storing data in Python are reflected by the two object properties `__dict__` and `__slots__`. Normally, all instance attributes (`self.foo`) are stored inside `__dict__` the dictionary, unless you define the `__slots__` attribute, in which case the object can only have a constant number of pre-defined attributes.
>
> I can understand if this is getting too confusing. Let me just show an example:
>
> > 现在有一个很长的解释。
> >
> > Python 实际上有两种在**对象内部存储数据**的方法：作为字典 (像大多数情况下)，和作为 "结构"。结构是一种 C 语言的数据类型，本质上可以被认为是 Python 的**元组**。字典使用更多的内存，因为它们可以随心所欲地**扩展**，并且**依靠额外的空间来保证其快速访问数据**的可靠性，这就是字典的特点。另一方面，Structs有一个固定的大小，不能被扩展，但它们占用的内存最少，因为它们把这些值一个接一个地打包，没有任何浪费的空间。
> >
> > 这两种在Python中存储数据的方式由两个对象属性`__dict__`和`__slots__`反映。通常，所有的实例属性 (`self.foo`) 都存储在`__dict__`这个字典里面，除非你定义了`__slots__`属性，在这种情况下，对象只能有一个固定数量的预定义属性。
> >
> > 我可以理解，如果这变得太混乱了。让我举一个例子:
>
> ```python
> >>> class NormalClass:
> ...     classvar = 'foo'
> ...     def __init__(self):
> ...         self.x = 1
> ...         self.y = 2
> ...
> >>> n = NormalClass()
> >>> n.__dict__
> {'x': 1, 'y': 2}  # Note that `classvar` variable isn't here.
> >>>               # That is stored in `NormalClass.__dict__`
> >>> class SlottedClass:
> ...     __slots__ = ('x', 'y')
> ...     classvar = 'foo'  # This is fine.
> ...     def __init__(self):
> ...         self.x = 1
> ...         self.y = 2
> ...         # Trying to create `self.z` here will cause the same
> ...         # `AttributeError` as before.
> ...
> >>> s = SlottedClass()
> >>> s.__dict__
> # this actually works, it print "{'x': 1, 'y': 2}", Does because the version of Python?
> AttributeError: 'SlottedClass' object has no attribute '__dict__'
> >>> s.__slots__
> ('x', 'y')
> ```
>
> So creating slots prevents a `__dict__` from existing, which means no dictionary to add new attributes into, and it also means saved memory. That's basically it.
>
> AnthonyWritesCode [made a video](https://www.youtube.com/watch?v=BSNd_kxHXL8) about another interesting piece of code relating to slots and their obscure behaviour, do check that out!
>
> > 所以创建slots可以防止一个`__dict__`的存在，这意味着没有字典可以添加新的属性，也意味着节省内存。基本上就是这样了。
> >
> > AnthonyWritesCode [做了一个视频](https://www.youtube.com/watch?v=BSNd_kxHXL8)，讲述了另一段与slot有关的有趣的代码和它们的晦涩的行为，请看一下!

### `hasattr`, `getattr`, `setattr`, and `delattr`: Attribute helpers

Now that we've seen that objects are pretty much the same as  dictionaries underneath, let's draw a few more paralells between them  while we are at it.

We know that accessing as well as reassigning a property inside a dictionary is done using indexing:

> 现在我们已经看到对象和字典底层的内容基本相同，让我们在它们之间再画一些平行线。
>
> 我们知道，访问以及重新赋值字典中的一个属性是通过**索引**来完成的：

```python
>>> dictionary = {'property': 42}
>>> dictionary['property']
42
```

while on an object it is done via the `.` operator:

```python
class C:
    prop = 42
    
>>> C.prop
42
```

You can even set and delete properties on objects:

```python
>>> C.prop = 84
>>> C.prop
84
>>> del C.prop
>>> C.prop
AttributeError: type object 'C' has no attribute 'prop'
```

But dictionaries are so much more flexible: you can for example, check if a property exists in a dictionary:

> 但字典要灵活得多：例如，你可以检查一个属性**是否存在于**一个字典中。
>

```python
>>> d = {}
>>> 'prop' in d
False
>>> d['prop'] = 'exists'
>>> 'prop' in d
True
```

You *could* do this in an object by using try-catch:

```python
>>> class X:
...    pass
...
>>> x = X()
>>> try:
...     print(x.prop)
>>> except AttributeError:
...     print("prop doesn't exist.")
prop doesn't exist.
```

But the preferred method to do this would be direct equivalent: `hasattr`.

> 但首选的方法是直接等价：`hasattr`。

```python
>>> class X:
...    pass
...
>>> x = X()
>>> hasattr(x, 'prop')
False
>>> x.prop = 'exists'
>>> hasattr(x, 'prop')
True
```

Another thing that dictionaries can do is using a variable to index a  dict. You can't really do that with objects, right? Let's try:

> 字典可以做的另一件事是用一个变量来**索引**一个dict。你真的不能用对象来做这个，对吗？让我们试试：

```python
>>> class X:
...     value = 42
...
>>> x = X()
>>> attr_name = 'value'
>>> x.attr_name
AttributeError: 'X' object has no attribute 'attr_name'
```

Yeah, it doesn't take the variable's value. This should be pretty obvious. But to actually do this, you can use `getattr`, which does take in a string, just like a dictionary key:

> 是的，它不接受变量的值。这应该是很明显的。但是要真正做到这一点，你可以使用 `getattr`，它确实接收一个字符串，就像一个字典的键。

```python
>>> class X:
...     value = 42
...
>>> x = X()
>>> getattr(x, 'value')
42
>>> attr_name = 'value'
>>> getattr(x, attr_name)
42  # It works!
```

`setattr` and `delattr` work the same way: they take in the attribute name as a string, and sets/deletes the corresponding attribute accordingly.

> `setattr`和`delattr`的工作方式相同：它们接收**属性名称**作为字符串，并相应地设置/删除相应的属性。

```python
>>> class X:
...     value = 42
...
>>> x = X()
>>> setattr(x, 'value', 84)
>>> x.value
84
>>> delattr(x, 'value')  # deletes the attribute completety
>>> hasattr(x, 'value')
False  # `value` no longer exists on the object.
```

Let's try to build something that kinda makes sense with one of these functions:

Sometimes you need to create a function that has to be overloaded to either take a value directly, or take a "factory" object, it can be an object or a  function for example, which generates the required value on demand.  Let's try to implement that pattern:

> 让我们试着用这些函数中的一个建立一些**有点**意义的东西。
>
> 有时你需要创建一个必须**重载**的函数，要么直接取值，要么取一个 "factory"对象，它可以是一个对象或一个函数，按要求生成**所需**的值。 让我们试着实现这种模式：

```python
class api:
    """A dummy API."""
    def send(item):
        print(f'Uploaded {item!r}!')

def upload_data(item):
    """Uploads the provided value to our database."""
    if hasattr(item, 'get_value'):
        data = item.get_value()
        api.send(data)
    else:
        api.send(item)
```

The `upload_data` function is checking if we have gotten a factory object, by checking if it has a `get_value` method. If it does, that function is used to get the actual value to upload. Let's try to use it!

> `upload_data`函数通过检查factory对象是否有`get_value`方法，来检查我们是否已经得到了一个factory对象。如果有，该函数将用于获取要上传的实际值。让我们试着使用它!

```python
>>> import json
>>> class DataCollector:
...     def __init__(self):
...         self.items = []
...     def add_item(self, item):
...         self.items.append(item)
...     def get_value(self):
...         return json.dumps(self.items)
...
>>> upload_data('some text')
Uploaded 'some text'!
>>> collector = DataCollector()
>>> collector.add_item(42)
>>> collector.add_item(1000)
>>> upload_data(collector)
Uploaded '[42, 1000]'!
```

### `super`: The power of inheritance

`super` is Python's way of referencing a superclass, to use its methods, for example.

Take this example, of a class that encapsulates the logic of summing two items:

> `super`是Python引用**超类**的方式，例如，使用它的方法。
>
> 以这个例子为例，一个封装了两个项目相加的逻辑的类：

```python
class Sum:
    def __init__(self, x, y):
        self.x = x
        self.y = y

    def perform(self):
        return self.x + self.y
```

Using this class is pretty simple:

```python
>>> s = Sum(2, 3)
>>> s.perform()
5
```

Now let's say you want to subclass `Sum` to create a a `DoubleSum` class, which has the same `perform` interface but it returns double the value instead. You'd use `super` for that:

> 现在我们假设你想把`Sum`子类化，创建一个`DoubleSum`类，它有相同的`perform`接口，但它返回双倍的值。你可以使用`super`来实现：

```python
class DoubleSum(Sum):
    def perform(self):
        parent_sum = super().perform()
        return 2 * parent_sum
```

We didn't need to define anything that was already defined: We didn't need to define `__init__`, and we didn't have to re-write the sum logic as well. We simply piggy-backed on top of the superclass.

> 我们不需要定义任何已经定义过的东西。我们不需要定义`__init__`，我们也不需要重新编写和的逻辑。我们只是简单地在超类的基础上搭了个便车。

```python
>>> d = DoubleSum(3, 5)
>>> d.perform()
16
```

Now there are some other ways to use the `super` object, even outside of a class:

> 现在有一些其他的方法来使用`super`对象，甚至在类之外：

```python
>>> super(int)
<super: <class 'int'>, NULL>
>>> super(int, int)
<super: <class 'int'>, <int object>>
>>> super(int, bool)
<super: <class 'int'>, <bool object>>
```

But honestly, I don't understand what these would ever be used for. If you know, let me know in the comments ✨

> 但说实话，我不明白这些东西会被用来做什么。如果你知道，请在评论中告诉我✨

### `property`, `classmethod` and `staticmethod`: Method decorators

We're reaching the end of all the class and object-related builtin functions, the last of it being these three decorators.

> 我们已经到达了所有**与类和对象**有关的内置函数的终点，最后一个是这三个**装饰器**。

`property`:

`@property` is the decorator to use when you want to  define getters and setters for properties in your object. Getters and  setters provide a way to add validation or run some extra code when  trying to read or modify the attributes of an object.

This is done by turning the property into a set of functions: one  function that is run when you try to access the property, and another  that is run when you try to change its value.

Let's take a look at an example, where we try to ensure that the  "marks" property of a student is always set to a positive number, as  marks cannot be negative:

> `@property`是一个装饰器，当你想为你的对象中的属性定义**获取器**和**设置器**时，可以使用。获取器和设置器提供了一种方法，当试图读取或修改一个对象的属性时，添加验证或运行一些额外的代码。
>
> 这是通过**将属性变成一组函数**来实现的：一个函数在你试图访问该属性时运行，另一个在你试图改变其值时运行。
>
> 让我们看一个例子，我们试图确保一个学生的 "分数"属性总是被设置为一个正数，因为分数不能是负数。

```python
class Student:
    def __init__(self):
        self._marks = 0

    @property
    def marks(self):
        return self._marks

    @marks.setter
    def marks(self, new_value):
        # Doing validation
        if new_value < 0:
            raise ValueError('marks cannot be negative')

        # before actually setting the value.
        self._marks = new_value
```

Running this code:

```python
>>> student = Student()
>>> student.marks
0
>>> student.marks = 85
>>> student.marks
85
>>> student.marks = -10
ValueError: marks cannot be negative
```

`classmethod`:

`@classmethod` can be used on a method to make it a class  method instead: such that it gets a reference to the class object,  instead of the instance (`self`).

A simple example would be to create a function that returns the name of the class:

> `@classmethod`可以用在一个方法上，使其成为一个**类方法**：这样它就可以得到一个对**类对象的引用**，而不是实例（`self`）。
>
> 一个简单的例子是创建一个函数来返回类的名称：

```python
>>> class C:
...     @classmethod
...     def class_name(cls):
...         return cls.__name__
...
>>> x = C()
>>> x.class_name
'C'
```

`staticmethod`: `@staticmethod` is used to convert a method into a static  method: one equivalent to a function sitting inside a class, independent of any class or object properties. Using this completely gets rid of  the first `self` argument passed to methods.

We could make one that does some data validation for example:

> `staticmethod`: `@staticmethod`用于将一个方法转换为**静态方法**：相当于一个位于类中的函数，与任何**类或对象的属性**无关。使用这个方法完全摆脱了传递给方法的第一个`self`参数。
>
> 例如，我们可以做一个做一些数据验证的方法：

```python
class API:
    @staticmethod
    def is_valid_title(title_text):
        """Checks whether the string can be used as a blog title."""
        return title_text.istitle() and len(title_text) < 60
```

These builtins are created using a pretty advanced topic called **descriptors**. I'll be honest, descriptors are a topic that is so advanced that trying to cover it here won't be of any use beyond what has already been told. I'm planning on writing a detailed article on descriptors and their  uses sometime in the future, so stay tuned for that!

> 这些**内置程序**是用一个相当高级的话题创建的，这个话题叫做**描述符**。老实说，描述符是一个非常高级的话题，在这里试图涵盖它，除了已经讲过的内容外，没有任何用处。我计划在未来的某个时候写一篇关于描述符及其用途的详细文章，所以请继续关注。

### `list`, `tuple`, `dict`, `set` and `frozenset`: The containers

A "container" in Python refers to a data structure that can hold any number of items inside it.

Python has 5 fundamental container types:

> 在Python中，"容器"指的是一个**数据结构**，它里面可以容纳**任何数量**的项目。
>
> Python 有 5 种基本的容器类型：

`list`: Ordered, indexed container. Every element is  present at a specific index. Lists are mutable, i.e. items can be added  or removed at any time.

> `list`: **有序**的、**有索引**的容器。每个元素都存在于一个特定的索引。列表是**可变的**，也就是说，项目可以在任何时候被添加或删除。

```python
>>> my_list = [10, 20, 30]  # Creates a list with 3 items
>>> my_list[0]              # Indexes start with zero
10
>>> my_list[1]              # Indexes increase one by one
20
>>> my_list.append(40)      # Mutable: can add values
>>> my_list
[10, 20, 30, 40]
>>> my_list[0] = 50         # Can also reassign indexes
>>> my_list
[50, 20, 30, 40]
```

`tuple`: Ordered and indexed just like lists, but with one key difference: They are *immutable*, which means items cannot be added or deleted once the tuple is created.

> `tuple`：顺序和索引就像列表一样，但有一个关键区别。它们是***不可变的***，这意味着一旦元组被创建，项目就不能被添加或删除。

```python
>>> some_tuple = (1, 2, 3)
>>> some_tuple[0]              # Indexable
1
>>> some_tuple.append(4)       # But NOT mutable
AttributeError: ...
>>> some_tuple[0] = 5          # Cannot reassign an index as well
TypeError: ...
```

`dict`: Unordered key-value pairs. The key is used to access the value. Only one value can correspond to a given key.

> `dict`。**无序的键-值对**。键是用来**访问值**的。一个给定的键只能对应一个值。

```python
>>> flower_colors = {'roses': 'red', 'violets': 'blue'}
>>> flower_colors['violets']               # Use keys to access value
'blue'
>>> flower_colors['violets'] = 'purple'    # Mutable
>>> flower_colors
{'roses': 'red', 'violets': 'purple'}
>>> flower_colors['daffodil'] = 'yellow'   # Can also add new values
>>> flower_colors
{'roses': 'red', 'violets': 'purple', 'daffodil': 'yellow'}
```

`set`: Unordered, unique collection of data. Items in a  set simply represent their presence or absence. You could use a set to  find for example, the kinds of trees in a forest. Their order doesn't  matter, only their existance.

> `set`：**无序**的、**唯一**的数据集合。集合中的项目只是代表它们的存在或不存在。你可以用一个集合来寻找，例如，森林中的树木种类。它们的顺序并不重要，只是它们的存在。

```python
>>> forest = ['cedar', 'bamboo', 'cedar', 'cedar', 'cedar', 'oak', 'bamboo']
>>> tree_types = set(forest)
>>> tree_types
{'bamboo', 'oak', 'cedar'}      # Only unique items
>>> 'oak' in tree_types
True
>>> tree_types.remove('oak')    # Sets are also mutable
>>> tree_types
{'bamboo', 'cedar'}
```

A `frozenset` is identical to a set, but just like `tuple`s, is immutable.

> 一个 `frozenset` 与一个set相同，但就像 `tuple` 一样，是不可改变的。

```python
>>> forest = ['cedar', 'bamboo', 'cedar', 'cedar', 'cedar', 'oak', 'bamboo']
>>> tree_types = frozenset(forest)
>>> tree_types
frozenset({'bamboo', 'oak', 'cedar'})
>>> 'cedar' in tree_types
True
>>> tree_types.add('mahogany')           # CANNOT modify
AttributeError: ...
```

The builtins `list`, `tuple` and `dict` can be used to create empty instances of these data structures too:

> 内建程序`list`、`tuple`和`dict`也可以用来创建这些数据结构的**空实例**。
>

```python
>>> x = list()
>>> x
[]
>>> y = dict()
>>> y
{}
```

But the short-form `{...}` and `[...]` is more readable and should be preferred. It's also a tiny-bit faster to use the short-form syntax, as `list`, `dict` etc. are defined inside builtins, and looking up these names inside the variable scopes takes some time, whereas `[]` is understood as a list without any lookup.

> 但短式的`{...}`和`[...]`更具可读性，应该是首选。使用短式语法也会快一点，因为`list`、`dict`等都是在内置程序中定义的，在变量范围内查找这些名字需要一些时间，而`[]`则被理解为一个列表，不需要任何查找。

### `bytearray`, and `memoryview`: Better byte interfaces

A `bytearray` is the mutable equivalent of a `bytes` object, pretty similar to how lists are essentially mutable tuples.

`bytearray` makes a lot of sense, as:

> `bytearray` 是 `bytes` 对象的**可变等价物**，与**列表本质上是可变元组**的情况非常相似。
>
> `bytearray`有很大的意义，因为：

A lot of low-level interactions have to do with byte and bit manipulation, like this [horrible implementation for `str.upper`](https://twitter.com/sadhlife/status/1441654357691305989), so having a byte array where you can mutate individual bytes is going to be much more efficient.

Bytes have a fixed size (which is... 1 byte). On the other hand,  string characters can have various sizes thanks to the unicode encoding  standard, "utf-8":

> 很多底层的交互都与字节和位的操作有关，比如这个[可怕的`str.upper`的实现](https://twitter.com/sadhlife/status/1441654357691305989)，所以有一个字节数组，你可以改变单个字节，这将会更有效率。
>
> 字节有一个固定的大小（也就是......1个字节）。另一方面，由于unicode编码标准 "utf-8 "的存在，字符串字符可以有各种大小：

```python
>>> x = 'I♥🐍'
>>> len(x)
3
>>> x.encode()
b'I\xe2\x99\xa5\xf0\x9f\x90\x8d'
>>> len(x.encode())
8
>>> x[2]
'🐍'
>>> x[2].encode()
b'\xf0\x9f\x90\x8d'
>>> len(x[2].encode())
4
```

So it turns out, that the three-character string 'I♥🐍' is actually  eight bytes, with the snake emoji being 4 bytes long. But, in the  encoded version of it, we can access each individual byte. And because  it's a byte, its "value" will always be between 0 and 255:

> 因此，事实证明，三个字符的字符串 "I♥🐍"实际上是八个字节，其中蛇形表情符号有四个字节长。但是，在它的编码版本中，我们可以访问每个单独的字节。而且，因为它是一个字节，它的 "值"将总是在0和255之间。

```python
>>> x[2]
'🐍'
>>> b = x[2].encode()
>>> b
b'\xf0\x9f\x90\x8d'  # 4 bytes
>>> b[:1]
b'\xf0'
>>> b[1:2]
b'\x9f'
>>> b[2:3]
b'\x90'
>>> b[3:4]
b'\x8d'
>>> b[0]  # indexing a bytes object gives an integer
240
>>> b[3]
141
```

So let's take a look at some byte/bit manipulation examples:

> 因此，让我们看一下一些字节/位操作的例子：

```python
def alternate_case(string):
    """Turns a string into alternating uppercase and lowercase characters."""
    array = bytearray(string.encode())
    for index, byte in enumerate(array):
        if not ((65 <= byte <= 90) or (97 <= byte <= 126)):
            continue

        if index % 2 == 0:
            array[index] = byte | 32
        else:
            array[index] = byte & ~32

    return array.decode()

>>> alternate_case('Hello WORLD?')
'hElLo wOrLd?'
```

This is not a good example, and I'm not going to bother explaining  it, but it works, and it is much more efficient than creating a new `bytes` object for every character change.

Meanwhile, a `memoryview` takes this idea a step further: It's pretty much just like a bytearray, but it can refer to an object or a slice *by reference*, instead of creating a new copy for itself. It allows you to pass  references to sections of bytes in memory around, and edit it in-place:

> 这不是一个好的例子，我也懒得解释，但它是有效的，而且比为每个字符的变化创建一个新的`bytes`对象要有效得多。
>
> 同时，`memoryview`将这一想法向前推进了一步。它和字节数差不多，但它可以通过引用*来引用*一个对象或一个片断，而不是为自己创建一个新的副本。它允许你在内存中传递对字节段的引用，并在原地编辑：

```python
>>> array = bytearray(range(256))
>>> array
bytearray(b'\x00\x01\x02\x03\x04\x05\x06\x07\x08...
>>> len(array)
256
>>> array_slice = array[65:91]  # Bytes 65 to 90 are uppercase english characters
>>> array_slice
bytearray(b'ABCDEFGHIJKLMNOPQRSTUVWXYZ')
>>> view = memoryview(array)[65:91]  # Does the same thing,
>>> view
<memory at 0x7f438cefe040>  # but doesn't generate a new new bytearray by default
>>> bytearray(view)
bytearray(b'ABCDEFGHIJKLMNOPQRSTUVWXYZ')  # It can still be converted, though.
>>> view[0]  # 'A'
65
>>> view[0] += 32  # Turns it lowercase
>>> bytearray(view)
bytearray(b'aBCDEFGHIJKLMNOPQRSTUVWXYZ')  # 'A' is now lowercase.
>>> bytearray(view[10:15])
bytearray(b'KLMNO')
>>> view[10:15] = bytearray(view[10:15]).lower()
>>> bytearray(view)
bytearray(b'aBCDEFGHIJklmnoPQRSTUVWXYZ')  # Modified 'KLMNO' in-place.
```

### `bin`, `hex`, `oct`, `chr`, and `ascii`: Basic conversions

The `bin`, `hex` and `oct` triplet  is used to convert between bases in Python. You give them a number, and  they will spit out how you can write that number in that base in your  code:

> `bin`、`hex` 和 `oct` 三要素用于在Python中进行**基数转换**。你给他们一个数字，他们会吐出你如何在你的代码中用这个基数写这个数字。

```python
>>> bin(42)
'0b101010'
>>> hex(42)
'0x2a'
>>> oct(42)
'0o52'
>>> 0b101010
42
>>> 0x2a
42
>>> 0o52
42
```

Yeah, you can write numbers in base 2, base 8 or base 16 in your code if you really want to. In the end, they are all completely identical to the integers wriiten in regular decimal:

> 是的，如果你真的想的话，你可以在你的代码中写成基数2、基数8或基数16的数字。最后，它们都与用普通十进制写的整数完全相同。
>

```python
>>> type(0x20)
<class 'int'>
>>> type(0b101010)
<class 'int'>
>>> 0o100 == 64
True
```

But there are times where it makes sense to use other bases instead, like when writing bytes:

> 但在有些时候，使用其他基数是有意义的，比如在写字节时：

```python
>>> bytes([255, 254])
b'\xff\xfe'              # Not very easy to comprehend
>>> # This can be written as:
>>> bytes([0xff, 0xfe])
b'\xff\xfe'              # An exact one-to-one translation
```

Or when writing OS-specific codes that are implemented in octal, for example:

> 或者在编写以八进制实现的操作系统特定代码时，比如说：

```python
import os
>>> os.open('file.txt', os.O_RDWR, mode=384)    # ??? what's 384
>>> # This can be written as:
>>> os.open('file.txt', os.O_RDWR, mode=0o600)  # mode is 600 -> read-write
```

Note that `bin` for example is only supposed to be used when  you want to create a binary-representation of a Python integer: If you  want a binary string it's better to use Python's string formatting:

> 注意，例如`bin`只应该在你想创建一个Python整数的二进制表示时使用。如果你想要一个二进制字符串，最好使用Python的字符串格式化。

```python
>>> f'{42:b}'
101010
```

`ord` and `chr` are used to convert ascii as well as unicode characters and their character codes:

> `ord`和`chr`用于转换ascii和unicode字符及其字符编码：

```python
>>> ord('x')
120
>>> chr(120)
'x'
>>> ord('🐍')
128013
>>> hex(ord('🐍'))
'0x1f40d'
>>> chr(0x1f40d)
'🐍'
>>> '\U0001f40d'  # The same value, as a unicode escape inside a string
'🐍'
```

It's pretty simple.

### `format`: Easy text transforms

`format(string, spec)` is just another way to do `string.format(spec)`.

Python's string formatting can do a lot of interesting things, like:

> `format(string, spec)`只是做`string.format(spec)`的另一种方式。
>
> Python 的字符串格式化可以做很多有趣的事情，比如：

```python
>>> format(42, 'c')             # int to ascii
'*'
>>> format(604, 'f')            # int to float
'604.000000'
>>> format(357/18, '.2f')       # specify decimal precision
'19.83'
>>> format(604, 'x')            # int to hex
'25c'
>>> format(604, 'b')            # int to binary
'1001011100'
>>> format(604, '0>16b')        # binary with zero-padding
'0000001001011100'
>>> format('Python!', '🐍^15')  # centered aligned text
'🐍🐍🐍🐍Python!🐍🐍🐍🐍'
```

I have an entire article on string formatting [right here](https://sadh.life/post/what-the-f-strings), so check that out for more.

> 我有一整篇关于字符串格式化的文章[就在这里](https://sadh.life/post/what-the-f-strings)，所以请查看那篇文章以了解更多。

### `any` and `all`

These two are some of my favorite builtins. Not because they are incredibly helpful or powerful, but just because how *Pythonic* they are. There's certain pieces of logic that can be re-written using `any` or `all`, which will instantly make it much shorter and much more readable, which is what Python is all about. Here's an example of one such case:

Let's say you have a bunch of JSON responses from an API, and you want to  make sure that all of them contain an ID field, which is exactly 20  characters long. You could write your code in this way:

> 这两个是我最喜欢的一些内置程序。不是因为它们有多大的帮助，也不是因为它们有多强大，而只是因为它们是多么的*Pythonic*。有一些逻辑片段可以用`any`或`all`来重写，这将立即使它变得更短、**更易读**，这正是Python的宗旨。这里有一个这样的例子。
>
> 假设你有一堆来自 API 的 JSON 响应，你想确保所有的响应都包含一个 ID **字段**，它的长度正好是 20 个字符。你可以这样写你的代码：

```python
def validate_responses(responses):
    for response in responses:
        # Make sure that `id` exists
        if 'id' not in response:
            return False
        # Make sure it is a string
        if not isinstance(response['id'], str):
            return False
        # Make sure it is 20 characters
        if len(response['id']) != 20:
            return False

    # If everything was True so far for every
    # response, then we can return True.
    return True
```

Or, we can write it in this way:

```python
def validate_responses(responses):
    return all(
        'id' in response
        and isinstance(response['id'], str)
        and len(response['id']) == 20
        for response in responses
    )
```

What `all` does is it takes in an iterator of boolean values, and it returns `False` if it encounters even a single `False` value in the iterator. Otherwise it returns `True`.

And I love the way to do it using `all`, because it reads exactly like english: "Return if id's exist, are integers and are 20 in length, in all responses."

Here's another example: Trying to see if there's any palindromes in the list:

> `all` 的作用是接收一个布尔值的迭代器，如果它在迭代器中遇到一个 `False` 的值，它将返回 `False`。否则返回 `True`。
>
> 我喜欢使用`all`的方式，因为它的读法和英文完全一样。"如果id存在，是整数，并且长度为20，在所有的响应中，返回。"
>
> 下面是另一个例子。试图查看列表中是否有任何回文字符：

```python
def contains_palindrome(words):
    for word in words:
        if word == ''.join(reversed(word)):
            return True

    # Found no palindromes in the end
    return False
```

vs.

```python
def contains_palindrome(words):
    return any(word == ''.join(reversed(word)) for word in words)
```

And with the wording I believe it should be obvious, that `any` does the opposite of all: it returns `True` if even one value is `True`, otherwise it returns `False`.

> 我相信这个措辞应该很明显，`any`做的是与all相反的事情：如果有一个值是`True`，它就返回`True`，否则就返回`False`。
>

> Extras: listcomps inside any/all
>
> Note that the code using `any` or `all` could've also been written as a list comprehension:
>
> > 请注意，使用`any`或`all`的代码也可以写成一个列表推导式：
>
> ```python
> >>> any([num == 0 for num in nums])
> ```
>
> Instead of a generator expression:
>
> ```python
> >>> any(num == 0 for num in nums)
> ```
>
> Notice the lack of `[]` square brackets in the second one. And you should always prefer using a generator expression in this case, because of how generators work in Python.
>
> Generators are constructs that generate new values *lazily*.  What this means is that instead of computing and storing all the values  inside a list, it generates one value, provides it to the program, and  only generates the next value when it is required.
>
> This means that there's a **huge** difference between these two lines of code:
>
> > 注意第二个表达式中没有`[]`方括号。在这种情况下，你应该总是倾向于使用一个**生成器表达式**，因为生成器在 Python 中是如何工作的。
> >
> > 生成器是一种结构，可以*懒惰地*生成新的值。 这意味着它不是计算和存储一个列表中的所有值，而是生成一个值，提供给程序，并在需要时才生成下一个值。
> >
> > 这意味着这两行代码之间存在着**大的**差异：
>
> ```python
> >>> any(num == 10 for num in range(100_000_000))
> True
> >>> any([num == 10 for num in range(100_000_000)])
> True
> ```
>
> Not only does the second one store 100 million values in a list for no reason before running `all` over it, it also takes more than 10 seconds on my machine. Meanwhile,  because the first one is a generator expression, it generates numbers  from 0 to 10 one by one, gives them to `any`, and as soon as the count reaches 10, `any` breaks the iteration and returns `True` almost instantly. Which also means, that it practically runs 10 million times faster in this case.
>
> So, yeah. Never pass list comprehensions inside `any` or `all` when you can pass a generator instead.
>
> > 第二个表达式在运行 `all` 之前无缘无故地**在一个列表中存储**了1亿个值，而且在我的机器上需要超过10秒。同时，因为第一个表达式是一个生成器表达式，它逐个生成从0到10的数字，并把它们交给`any`，一旦计数达到10，`any`就中断迭代并几乎立即返回`True`。这也意味着，在这种情况下，它的运行速度实际上要快1000万倍。
> >
> > 所以，是的。当你可以传递一个生成器时，千万不要在`any`或`all`中传递列表推导式。

### `abs`, `divmod`, `pow` and `round`: Math basics

These four math functions are so common in programming that they have been thrown straight into the builtins where they are always available, rather than putting them in the `math` module.

They're pretty straightforward:

> 这四个**数学函数**在编程中非常常见，所以它们被直接扔到了**内置模块**中，在那里它们总是可用的，而不是把它们放在`math`模块中。
>
> 它们非常简单明了：

- `abs` returns the absolute value of a number, eg:

  ```python
  >>> abs(42)
  42
  >>> abs(-3.14)
  3.14
  >>> abs(3-4j)
  5.0
  ```

- `divmod` returns the quotient and remainder after a divide operation:

  ```python
  >>> divmod(7, 2)
  (3, 1)
  >>> quotient, remainder = divmod(5327, 100)
  >>> quotient
  53
  >>> remainder
  27
  ```

- `pow` returns the exponent (power) of a value:

  ```python
  >>> pow(100, 3)
  1000000
  >>> pow(2, 10)
  1024
  ```

- `round` returns a number rounded to the given decimal precision:

  ```python
  >>> import math
  >>> math.pi
  3.141592653589793
  >>> round(math.pi)
  3
  >>> round(math.pi, 4)
  3.1416
  >>> round(1728, -2)
  1700
  ```

### `isinstance` and `issubclass`: Runtime type checking

You've already seen the `type` builtin, and using that knowledge you can already implement runtime type-checking if you need to, like this:

> 你已经看到了`type`内建函数，如果需要的话，利用这些知识你已经可以实现**运行时的类型检查**了，比如这样：

```python
def print_stuff(stuff):
    if type(stuff) is list:
        for item in stuff:
            print(item)
    else:
        print(stuff)
```

Here, we are trying to check if the item is a `list`, and if it is, we print each item inside it individually. Otherwise, we just print the item. And this is what the code does:

> 在这里，我们试图检查这个项目是否是一个 `list`，如果是，我们就单独打印里面的每个项目。否则，我们只打印这个项目。这就是代码的作用：

```python
>>> print_stuff('foo')
foo
>>> print_stuff(123)
123
>>> print_stuff(['spam', 'eggs', 'steak'])
spam
eggs
steak
```

It does work! So yeah, you can check, at runtime, the type of a  variable and change the behaviour of your code. But, there's actually  quite a few issues with the code above. Here's one example:

> 它确实起作用! 所以，是的，你可以在**运行时检查一个变量的类型**并改变你的代码行为。但是，上面的代码实际上有很多问题。下面是一个例子：
>

```python
>>> class MyList(list):
...     pass
...
>>> items = MyList(['spam', 'eggs', 'steak'])
>>> items
['spam', 'eggs', 'steak']
>>> print_stuff(items)
['spam', 'eggs', 'steak']
```

Welp, `items` is very clearly still a list, but `print_stuff` doesn't recognize it anymore. And the reason is simple, because `type(items)` is now `MyList`, not `list`.

> 很明显，`items`仍然是一个列表，但是`print_stuff`不认识它了。原因很简单，因为`type(items)`现在是`MyList`，不是`list`。

> This code seems to be violating one of the five SOLID principles, called "Liskov Substitution Principle". The principle says that "objects of a  superclass shall be replaceable with objects of its subclasses without  breaking the application". This is important for inheritance to be a  useful programming paradigm.
>
> > 这段代码似乎违反了SOLID五项原则中的一项，即 "Liskov替代原则"。该原则说："超类的对象应可被其子类的对象取代而不破坏应用"。这对于继承成为一个有用的编程范式是很重要的。

The underlying issue of our function is that it doesn't account for inheritence. And that's exactly what `isinstance` is for: It doesn't only check if an object is an instance of a class,  it also checks if that object is an instance of a sub-class:

> 我们的函数的根本问题是它没有考虑到**继承性**。而这正是`isinstance`的作用。它不仅检查一个对象是否是一个**类的实例**，它还检查该对象是否是一个**子类的实例**。
>

```python
# creat the subclasss of list: MyList
>>> class MyList(list):
...     pass
...
>>> items = ['spam', 'eggs', 'steak']
>>> type(items) is list
True
>>> isinstance(items, list)
True   # Both of these do the same thing
>>> items = MyList(['spam', 'eggs', 'steak'])
>>> type(items) is list
False  # And while `type` doesn't work,
>>> isinstance(items, list)
True   # `isinstance` works with subclasses too.
```

Similarly, `issubclass` checks if a class is a subclass of another class. The first argument for `isinstance` is an object, but for `issubclass` it's another class:

> 同样地，`issubclass`检查一个类是否是另一个类的子类。`isinstance`的第一个参数是一个对象，但`issubclass`的第一个参数是另一个类：

```python
>>> issubclass(MyList, list)
True
```

Replacing the `type` check with `isinstance`, the code above will follow [Liskov Substitution Principle](https://en.wikipedia.org/wiki/Liskov_substitution_principle). But, it can still be improved. Take this for example:

> 用`isinstance`代替`type`检查，上面的代码将遵循[Liskov Substitution Principle](https://en.wikipedia.org/wiki/Liskov_substitution_principle)。但是，它仍然可以被改进。以此为例：

```python
>>> items = ('spam', 'eggs', 'steak')
>>> print_stuff(items)
('spam', 'eggs', 'steak')
```

Obviously it doesn't handle other container types other than `list` as of now. You could try to work around this by checking for `isinstance` of list, tuple, dictionary, and so on. But how far? How many objects are you going to add support for?

For this case, Python gives you a bunch of "base classes", that you can use to test for certain "behaviours" of your class, instead of testing for  the class itself. In our case, the behaviour is being a container of  other objects, so aptly the base class is called `Container`:

> 很明显，它现在还不能处理除 `list` 以外的其他容器类型。你可以尝试通过检查列表、元组、字典等的`isinstance`来解决这个问题。但是到什么程度呢？你要增加对多少个对象的支持？
>
> 对于这种情况，Python 给了你一堆 "base classes"，你可以用它们来测试你的类的某些 "行为"，而不是测试类本身。在我们的例子中，这种行为是作为其他对象的容器，所以基类被称为 `Container`，很恰当：

```python
>>> from collections.abc import Container
>>> items = ('spam', 'eggs', 'steak')
>>> isinstance(items, tuple)
True
>>> isinstance(items, list)
False
>>> isinstance(items, Container)
True  # This works!
```

> We should've used the `Iterable` or `Collection` base class here, but that would behave differently for strings as strings are iterable, but aren't a container. That's why `Container` was chosen here. This is only for ease of explanation, and in  real-world code it is recommended to see exactly which base class is  appropriate for your use case. You can find that using the [docs](https://docs.python.org/3/library/collections.abc.html).
>
> > 我们应该在这里使用`Iterable`或`Collection`基类，但这对字符串的行为是不同的，因为字符串是可迭代的，但不是一个容器。这就是为什么这里选择了 `Cotainer`。这只是为了**便于**解释，在真实世界的代码中，建议看看到底哪个基类适合你的使用情况。你可以使用[docs](https://docs.python.org/3/library/collections.abc.html)找到。

Every container object type will return `True` in the check against the `Container` base class. `issubclass` works too:

> 每个容器对象类型在对 `Container` 基类的检查中都将返回 `True`。`issubclass`也可以：
>

```python
>>> from collections.abc import Container
>>> issubclass(list, Container)
True
>>> issubclass(tuple, Container)
True
>>> issubclass(set, Container)
True
>>> issubclass(dict, Container)
True
```

So adding that to our code, it becomes:

> 所以在我们的代码中加入这一点，就变成了：

```python
from collections.abc import Container

def print_stuff(stuff):
    if isinstance(stuff, Container):
        for item in stuff:
            print(item)
    else:
        print(stuff)
```

This style of checking for types actually has a name: it's called "duck typing".

> 这种检查类型的方式实际上有一个名字：它被称为 "鸭子类型"。

### `callable`, and duck typing basics

Famously, Python is referred to as a "duck-typed" language. What it  means is that instead of caring about the exact class an object comes  from, Python code generally tends to check instead if the object can  satisfy certain *behaviours* that we are looking for.

> 著名的是，Python被称为一种 "duck-typed"语言。它的意思是，Python代码通常倾向于检查对象是否满足我们正在寻找的某些*行为*，而不是关心一个对象来自哪个类。

In the words of Alex Martelli:

> "You don't really care for IS-A -- you really only care for  BEHAVES-LIKE-A-(in-this-specific-context), so, if you do test, this  behaviour is what you should be testing for.
>
> In other words, don't check whether it IS-a duck: check whether it  QUACKS-like-a duck, WALKS-like-a duck, etc, etc, depending on exactly  what subset of duck-like behaviour you need to play your language-games  with."
>
> > "你并不真正关心IS-A -- 你真正关心的是BEHAVES-LIKE-A-（在这个特定的背景下），所以，如果你要测试，这种行为就是你应该测试的。
> >
> > 换句话说，不要检查它是否是一只鸭子：检查它是否像鸭子一样呱呱叫，像鸭子一样走路，等等，等等，这取决于你需要用什么子集的类似鸭子的行为来玩你的语言游戏。"

To explain this, I'll give you a quick example:

Some items in Python can be "called" to return a value, like functions and classes, while others can't, and will raise a `TypeError` if you try:

> 为了解释这个问题，我给你举个简单的例子。
>
> 在Python中，有些项目可以被 "调用 "来返回一个值，比如**函数和类**，而有些则不能，如果你尝试，会引发一个`TypeError`。
>

```python
>>> def magic():
...     return 42
...
>>> magic()  # Works fine
42
>>> class MyClass:
...     pass
...
>>> MyClass()  # Also works
<__main__.MyClass object at 0x7f2b7b91f0a0>
>>> x = 42
>>> x()  # Doesn't work
TypeError: 'int' object is not callable
```

How do you even begin to check if you can try and "call" a function,  class, and whatnot? The answer is actually quite simple: You just see if the object implements the `__call__` special method.

> 你甚至如何开始检查你是否可以尝试 "调用 "一个函数、类，以及其他什么？答案其实很简单。你只需看看该对象是否实现了`__call__`特殊方法。

```python
>>> def is_callable(item):
...     return hasattr(item, '__call__')
...
>>> is_callable(list)
True
>>> def function():
...     pass
...
>>> is_callable(function)
True
>>> class MyClass:
...     pass
...
>>> is_callable(MyClass)
True
>>> is_callable('abcd')
False
```

And that's pretty much what the `callable` builtin does:

```python
>>> callable(list)
True
>>> callable(42)
False
```

By the way, these "special methods" is how most of Python's syntax and functionality works:

- `x()` is the same as doing `x.__call__()`
- `items[10]` is the same as doing `items.__getitem__(10)`
- `a + b` is the same as doing `a.__add__(b)`

Nearly every python behavior has an underlying "special method", or what they're sometimes called as, "dunder method" defined  underneath.

If you want to read more into these dunder methods, you can read the documentation page about [Python's data model](https://docs.python.org/3/reference/datamodel.html).

> 顺便说一下，这些 "特殊方法 "是Python的大部分语法和功能的工作方式。
>
> - `x()`与做`x.__call__()`是一样的。
> - `items[10]`等于做`items.__getitem__(10)`。
> - `a + b`等同于做`a.__add__(b)`。
>
> 几乎每一个python行为都有一个底层的 "特殊方法"，或者有时被称为 "dunder方法"，定义在下面。
>
> 如果你想进一步了解这些dunder方法，你可以阅读关于[Python的数据模型](https://docs.python.org/3/reference/datamodel.html)的文档页面。
>

### `sorted` and `reversed`: Sequence manipulators

Sorting and reversing a sequence of data are probably the most used  algorithmic operations in any programming language. And the top level `sorted` and `reversed` let you do exactly that.

> 对数据序列进行排序和反转可能是任何编程语言中最常用的算法操作。而顶层的`sorted`和`reversed`正是让你做到这一点。

- `sorted` This function sorts the incoming data, and returns a sorted `list` type.

  ```python
  >>> items = (3, 4, 1, 2)
  >>> sorted(items)
  [1, 2, 3, 4]
  ```

  It uses the "TimSort" algorithm created by by Tim Peters, one of the earliest Python wizards.

  There's also two other parameters that `sorted` can take: `reverse`, which when set to `True` sorts the data in reverse order; and `key`, which takes in a function that is used on every element to sort the  data based on a custom property of each item. Let's take a look at it:

  > 它使用Tim Peters创造的 "TimSort "算法，他是最早的Python向导之一。
  >
  > `sorted`还可以接受另外两个参数：`reverse`，当设置为`True`时，它以相反的顺序对数据进行排序；`key`，它接受一个函数，用于每个元素，根据每个项目的自定义属性对数据进行排序。让我们看一下。

  ```python
  >>> items = [
  ...   {'value': 3},
  ...   {'value': 1},
  ...   {'value': 2},
  ... ]
  >>> sorted(items, key=lambda d: d['value'])
  [{'value': 1}, {'value': 2}, {'value': 3}]
  >>> names = ['James', 'Kyle', 'Max']
  >>> sorted(names, key=len)  # Sorts by name length
  ['Max', 'Kyle', 'James']
  ```

  Also note, that while `list.sort()` is already one way to sort lists, the `.sort()` method only exists on lists, while `sorted` can take any iterable.

  > 还要注意的是，虽然`list.sort()`已经是对列表进行排序的一种方法，但`.sort()`方法只存在于列表上，而`sorted`可以接受**任何可迭代对象**。

- `reversed`

`reversed` is a function that takes in any sequence type and returns a **generator**, which yields the values in reversed order.

Returning a generator is nice, as this means that reversing certain objects takes no extra memory space at all, like `range` or `list`, whose reverse values can be generated one by one.

> `reversed`是一个函数，它接收任何序列类型并返回一个**生成器**，该生成器以**相反的**顺序产生数值。
>
> 返回一个生成器是很好的，因为这意味着反转某些对象根本**不需要额外的内存空间**，比如`range`或`list`，它们的反转值可以一个一个地生成。

```python
>>> items = [1, 2, 3]
>>> x = reversed(items)
>>> x
<list_reverseiterator object at 0x7f1c3ebe07f0>
>>> next(x)
3
>>> next(x)
2
>>> next(x)
1
>>> next(x)
StopIteration # Error: end of generator
>>> for i in reversed(items):
...     print(i)
...
3
2
1
>>> list(reversed(items))
[3, 2, 1]
```

### `map` and `filter`: Function primitives

Now in Python, everything might be an object, but that doesn't  necessarily mean that your Python code needs to be object-oriented. You  can in-fact write pretty easy to read *functional* code in Python.

If you don't know what functional languages or functional code is, the  idea is that all functionality is provided via functions. There isn't a  formal concept of classes and objects, inheritance and the like. In  essence, all programs simply manipulate pieces of data, by passing them  to functions and getting the modified values returned back to you.

> 现在在Python中，一切都可能是一个**对象**，但这并不一定意味着你的Python代码需要是**面向对象**的。事实上，你可以在Python中写出非常容易阅读的*功能*代码。
>
> 如果你不知道什么是函数式语言或函数式代码，其概念是**所有的功能都是通过函数提供**的。没有类和对象的正式概念，也没有继承和类似的概念。从本质上讲，所有的程序都是**通过将数据传递给函数，并将修改后的值返回给你，来简单地操作数据块**。

- `map`

  `map` is a "higher order function", which just means that it's a function that takes in another function as an argument.

  What `map` really does is it maps from one set of values to another. A really simple example would be a square mapping:

  > `map`是一个 "高阶函数"，这意味着它是一个**将另一个函数作为参数**的函数。
  >
  > `map`的真正作用是将一组数值映射到另一组。一个非常简单的例子是平方映射。

  ```python
  >>> def square(x):
  ...     return x * x
  ...
  >>> numbers = [8, 4, 6, 5]
  >>> list(map(square, numbers))
  [64, 16, 36, 25]
  >>> for squared in map(square, numbers):
  ...     print(squared)
  ...
  64
  16
  36
  25
  ```

  `map` takes two arguments: a function, and a sequence. It  simply runs that function with each element as input, and it stores all  the outputs inside a new list. `map(square, numbers)` took each of the numbers and returned a list of squared numbers.

  Note that I had to do `list(map(square, numbers))`, and this is because `map` itself returns a generator. The values are lazily mapped one at a time  as you request them, e.g. if you loop over a map value, it will run the  map function one by one on each item of the sequence. This means that  map doesn't store a complete list of mapped values and doesn't waste  time computing extra values when not needed.

  > `map`需要两个参数：一个**函数**和一个**序列**。它简单地以每个元素作为输入运行该函数，并将所有输出存储在一个新的列表中。`map(square, numbers)`接收每个数字并返回一个平方数的列表。
  >
  > 注意，我不得不做`list(map(square, numbers))`，这是因为`map`本身**返回一个生成器**。当你请求时，这些值被懒散地逐一映射，例如，如果你在一个map值上循环，它将对序列中的每项逐一运行map函数。这意味着map不会存储一个完整的映射值列表，也不会在不需要时浪费时间计算额外的值。

- `filter`

  `filter` is quite similar to `map`, except it doesn't map every value to a new value, it filters a sequence of values based on a *condition*.

  This means that the output of a filter will contain the same items as the ones that went in, except some may be discarded.

  A really simple example would be to filter out odd numbers from a result:

  > `filter`和`map`很相似，只是它不是把每个值都映射成一个新的值，而是根据一个*条件*来过滤一个值的序列。
  >
  > 这意味着过滤器的输出将包含与输入相同的项目，除了一些可能被丢弃。
  >
  > 一个非常简单的例子是过滤掉一个结果中的奇数。

  ```python
  >>> items = [13, 10, 25, 8]
  >>> evens = list(filter(lambda num: num % 2 == 0, items))
  >>> evens
  [10, 8]
  ```

  A few people might have realised that these functions are essentially doing the same thing as list comprehensions, and you'd be right!

  List comprehensions are basically a more Pythonic, more readable way to write these exact same things:

  > 有些人可能已经意识到，这些函数本质上是在**做与列表推导式相同的事情**，对的！
  >
  > 列表推导式基本上是一种更加Pythonic的、更加可读的写法。

  ```python
  >>> def square(x):
  ...     return x * x
  ...
  >>> numbers = [8, 4, 6, 5]
  >>> [square(num) for num in numbers]
  [64, 16, 36, 25]
  ```

  ```python
  >>> items = [13, 10, 25, 8]
  >>> evens = [num for num in items if num % 2 == 0]
  >>> evens
  [10, 8]
  ```

  You are free to use whichever syntax seems to suit your usecase better.

  > 你可以自由地使用哪种语法看起来更适合你的用例。

### `len`, `max`, `min` and `sum`: Aggregate functions

Python has a few *aggregate* functions: functions that combine a collection of values into a single result.

I think just a little code example should be more than enough to explain these four:

> Python 有几个*聚合*的函数：**将一组值组合成一个结果的函数**。
>
> 我想只用一个小小的代码例子来解释这四个函数应该是绰绰有余的。
>

```python
>>> numbers = [30, 10, 20, 40]
>>> len(numbers)
4
>>> max(numbers)
40
>>> min(numbers)
10
>>> sum(numbers)
100
```

Three of these can infact take any container data type, like sets, dictionaries and even strings:

> 其中三个实际上可以接受**任何容器数据类型**，如集合、字典，甚至字符串。

```python
>>> author = 'guidovanrossum'
>>> len(author)
14
>>> max(author)
'v'
>>> min(author)
'a'
```

`sum` is required to take in a container of numbers. Which means, this works:

> `sum`被要求接收一个数字容器。这意味着，这样做可以：

```python
>>> sum(b'guidovanrossum')
1542
```

I'll leave that to you to figure out what happened here ;)

### `iter` and `next`: Advanced iteration

`iter` and `next` define the mechanism through which a for loop works.

A for loop that looks like this:

> `iter`和`next`定义了for循环的工作机制。
>
> 一个for循环看起来像这样：

```python
for item in mylist:
    print(item)
```

is actually doing something like this internally:

```python
mylist_iterable = iter(mylist)
while True:
    try:
        item = next(mylist_iterable)

        print(item)

    except StopIteration:
        break
```

A  for-loop in Python is a cleverly disguised while loop. When you iterate  over a list, or any other datatype that supports iteration, it just  means that it understands the `iter` function, and returns an "iterator" object.

Iterator objects in Python do two things:

- They yield new values everytime you pass them to `next`
- They raise the `StopIteration` builtin exception when the iterator has run out of values.

This is how all for loops work.

BTW, generators also follow the iterator protocol:

> Python 中的 for 循环是一个经过巧妙伪装的 while 循环。当你在一个列表上迭代时，或者任何其它支持迭代的数据类型，只是意味着它理解 `iter` 函数，并返回一个 "iterator" 对象。
>
> Python 中的迭代器对象做两件事。
>
> - 每次你把它们传给`next`时，它们都会产生新的值
> - 当迭代器的值用完时，它们会引发 `StopIteration`内置异常。
>
> 这就是所有for循环的工作方式。
>
> BTW，生成器也遵循迭代器协议。
>

```python
>>> gen = (x**2 for x in range(1, 4))
>>> next(gen)
1
>>> next(gen)
4
>>> next(gen)
9
>>> next(gen)
Error: StopIteration
```

### `range`, `enumerate` and `zip`: Convenient iteration

You already know about `range`. It takes in upto 3 values, and returns an iterable that gives you integer values:

> 你已经知道了`range`。它最多接收3个值，并返回一个可迭代的值，给你整数值。

```python
>>> list(range(10))
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
>>> list(range(3, 8))
[3, 4, 5, 6, 7]
>>> list(range(1, 10, 2))
[1, 3, 5, 7, 9]
>>> list(range(10, 1, -2))
[10, 8, 6, 4, 2]
```

But `enumerate` and `zip` are actually really useful as well.

`enumerate` is great for when you need to access the index and value of elements in a list.

Instead of doing:

```python
>>> menu = ['eggs', 'spam', 'bacon']
>>> for i in range(len(menu)):
...     print(f'{i+1}: {menu[i]}')
...
1: eggs
2: spam
3: bacon
```

You can do this instead:

```python
>>> menu = ['eggs', 'spam', 'bacon']
>>> for index, item in enumerate(menu, start=1):
...     print(f'{index}: {item}')
...
1: eggs
2: spam
3: bacon
```

Similarly, `zip` is used to get index-wise values from multiple iterables.

Instead of doing:

```python
>>> students = ['Jared', 'Brock', 'Jack']
>>> marks = [65, 74, 81]
>>> for i in range(len(students)):
...     print(f'{students[i]} got {marks[i]} marks')
...
Jared got 65 marks
Brock got 74 marks
Jack got 81 marks
```

You can do:

```python
>>> students = ['Jared', 'Brock', 'Jack']
>>> marks = [65, 74, 81]
>>> for student, mark in zip(students, marks):
...     print(f'{student} got {mark} marks')
...
Jared got 65 marks
Brock got 74 marks
Jack got 81 marks
```

Both can help massively simplify iteration code.

> 两者都可以帮助**大规模地简化**迭代代码。

### `slice`

A `slice` object is what's used under the hood when you try to slice a Python iterable.

In `my_list[1:3]` for example, `[1:3]` is not the special part, only `1:3` is. The square brackets are still trying to index the list! But `1:3` *inside* these square brackets here actually creates a `slice` object.

This is why, `my_list[1:3]` is actually equivalent to `my_list[slice(1, 3)]`:

> `slice`对象是当你试图对一个Python可迭代对象进行切片时，在引擎下使用的东西。
>
> 以 `my_list[1:3]`为例，`[1:3]`不是特殊部分，只有`1:3`是。方括号仍然在试图对列表进行索引! 但是`1:3`在这些方括号的内部实际上创建了一个`切片`对象。
>
> 这就是为什么，`my_list[1:3]`实际上等同于`my_list[slice(1, 3)]`。
>

```python
>>> my_list = [10, 20, 30, 40]
>>> my_list[1:3]
[20, 30]
>>> my_list[slice(1, 3)]
[20, 30]
>>> nums = list(range(10))
>>> nums
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
>>> nums[1::2]
[1, 3, 5, 7, 9]
>>> s = slice(1, None, 2)  # Equivalent to `[1::2]`
>>> s
slice(1, None, 2)
>>> nums[s]
[1, 3, 5, 7, 9]
```

If you want to learn a bit more about slices, how they work and what all  can be done with them, I cover that in a separate article [here](https://sadh.life/post/slices).

> 如果你想了解更多关于切片的信息，它们是如何工作的，以及可以用它们做什么，我在另一篇文章中介绍了这一点[这里](https://sadh.life/post/slices)。
>

### `breakpoint`: built-in debugging

`breakpoint` was a builtin that was added to Python 3.7, as an easier way to drop into a debugging session. Essentially it just calls `set_trace()` from the `pdb` module, which is the debugger module that is built into Python.

What `pdb` lets you do is stop the execution of your code at any moment, inspect  the values of variables, run some code if you like, and then you can  even do fancy things like running the code one line at a time, or check  the state of the stack frames inside the interpreter.

Using `pdb` to debug your code, by slowly going over it, seeing which lines of code get executed, and inspecting values of objects and variables is a much  more efficient way to debug your code than using `print` statements.

Unfortunately there isn't any good way to show a debugger being used in a text-format in a blog. But, AnthonyWritesCode has a [really good video](https://www.youtube.com/watch?v=0LPuG825eAk) explaining some of its features if you're interested.

> `breakpoint`是Python 3.7中加入的一个内建程序，是进入**调试会话**的一个更简单的方法。本质上，它只是从`pdb`模块中调用`set_trace()`，而`pdb`是Python中内置的调试器模块。
>
> `pdb`可以让你在任何时候停止你的代码的执行，检查变量的值，如果你喜欢的话，可以运行一些代码，然后你甚至可以做一些花哨的事情，比如一次运行代码，或者检查解释器**内堆栈框架**的状态。
>
> 使用`pdb`来调试你的代码，通过慢慢浏览，看哪几行代码被执行，并检查对象和变量的值，是一种比使用`print`语句更有效的调试代码的方法。
>
> 不幸的是，没有任何好的方法可以在博客中以文本的形式显示调试器的使用情况。但是，AnthonyWritesCode有一个[非常好的视频](https://www.youtube.com/watch?v=0LPuG825eAk)解释了它的一些功能，如果你有兴趣的话。

### `open`: File I/O

`open` is the function that lets you read and write to files.

It's... actually rather straightforward, and there aren't any obscure things  about it that I can explain, so I'm not even going to bother with it.  You can read the [official docs](https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files) about reading and writing files if you'd like to know more.

> `open`是一个让你读写文件的函数。
>
> 它......实际上相当简单，而且没有任何我可以解释的晦涩的东西，所以我甚至不打算费力地去解释它。 如果你想知道更多，你可以阅读关于读写文件的[官方文档](https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files)。

### `repr`: Developer convenience

 `repr` is an interesting one. Its intended use-case is simply to help the developers.

`repr` is used to create a helpful string representation of an object,  hopefully one that concisely describes the object, and its current  state. The intent of this is to be able to debug simple issues simply by looking at the object's repr, instead of having to probe into ints  attributes at every step.

Here's a good example:

> `repr`是一个有趣的例子。它的目的是为了帮助开发者。
>
> `repr`用于创建一个对象的有用的**字符串表示**，希望它能**简明地描述该对象及其当前状态**。这样做的目的是为了能够简单地通过查看对象的repr来调试简单的问题，而不是在每一步都要探究ints属性。
>
> 这里有一个很好的例子：

```python
>>> class Vector:
...     def __init__(self, x, y):
...         self.x = x
...         self.y = y
...
>>> v = Vector(3, 5)
>>> v
<__main__.Vector object at 0x7f27dff5a1f0>
```

The default `repr` is not helpful at all. You'd have to manually check for its attributes:

> 默认的`repr`根本没有帮助。你必须手动检查它的属性。

```python
>>> dir(v)
['__class__', ... , 'x', 'y']
>>> v.x
3
>>> v.y
5
```

But, if you implement a friendly `repr` to it:

```python
>>> class Vector:
...     def __init__(self, x, y):
...         self.x = x
...         self.y = y
...     def __repr__(self):
...         return f'Vector(x={self.x}, y={self.y})'
>>> v = Vector(3, 5)
>>> v
Vector(x=3, y=5)
```

Now you don't need to wonder what this object contains. It's right in front of you!

### `help`, `exit`, and `quit`: site builtins

Now, these builtins aren't *real* builtins. As in, they aren't really defined in the `builtins` module. Instead, they are defined in the `site` module, and then injected into builtins when `site` module runs.

`site` is a module that is automatically run by default when you start Python. It is responsible for setting up a few useful things, including making  pip packages available for import, and setting up tab completion in the  REPL, among other things.

One more thing that it does is setup these few useful global functions:

- `help` is used to find documentation of modules and objects. It's equivalent to calling `pydoc.doc()`.
- `exit` and `quit` quit the Python process. Calling them is equivalent to calling `sys.exit()`.

> 现在，这些内置模块并不是*真正的*内置模块。也就是说，它们并没有真正定义在 `builtins` 模块中。相反，它们被定义在 `site` 模块中，然后在 `site` 模块运行时**被注入内建程序**。
>
> `site` 是一个在**启动 Python 时自动运行的模块**。它负责设置一些有用的东西，包括使 pip 包可以被导入，以及在 REPL 中设置标签完成，还有其他一些事情。
>
> 它还做了一件事，就是设置一些有用的全局函数。
>
> - `help`是用来查找模块和对象的文档。它相当于调用`pydoc.doc()`。
> - `exit`和`quit`退出Python进程。调用它们相当于调用 `sys.exit()`。

### `copyright`, `credits`, `license`: Important texts

 These three texts are also defined by the site module, and typing them in the REPL prints out their text, with `license()` being an interactive session.

>  这三个文本也是由site模块定义的，在REPL中输入它们会打印出它们的文本，其中`license()`是一个交互式会话。

## So what's next?

Well, here's the deal. *Python is huge.*

Here's just a few things that we haven't even touched upon yet:

- Threading / Multiprocessing
- Asynchoronous computation
- Type annotations
- Metaclasses
- Weak references
- The 200 or so builtin modules that do everything from html templating, to sending emails, to cryptography.

And that's probably not even all of it.

**But**, the important thing is that you know a LOT about Python's fundamentals  now. You know what makes Python tick, you understand its strengths.

The rest of the things you can pick up as you go, you just need to be aware that they exist!

The official Python tutorial has a section on the [builtin modules](https://docs.python.org/3/tutorial/stdlib.html), and the documentation around all of them is actually really good.  Reading that whenever you need it will pretty much help you figure out  everything as you need it.

There's also [more than 300 detailed videos](https://www.youtube.com/watch?v=qvkppppy9K8&list=PLWBKAf81pmOaP9naRiNAqug6EBnkPakvY) made by AnthonyWritesCode that are really informative.

So now that you've learned all of this, why don't you build something great?

> 好吧，事情是这样的。*Python是巨大的*。
>
> 这里只是一些我们还没有触及的东西。
>
> - 线程/多处理（Threading/Multiprocessing）
> - 异步计算（Asynchoronous computation）
> - 类型注释（type annotation）
> - 元类（Metaclasses）
> - 弱引用（weak reference）
> - 200个左右的内置模块，从html模板，到发送电子邮件，再到密码学，无所不包。
>
> 而这可能还不是全部。
>
> **但是**，重要的是你现在对 Python 的基础知识有了很多了解。你知道是什么让 Python 运转，你了解它的优势。
>
> 其余的东西你可以边走边学，你只需要意识到它们的存在即可
>
> 官方的 Python 教程中有一节是关于 [内置模块](https://docs.python.org/3/tutorial/stdlib.html)，而且围绕所有这些模块的文档实际上都非常好。 每当你需要的时候，阅读这些文档几乎可以帮助你在需要的时候弄清一切。
>
> 还有AnthonyWritesCode制作的[300多个详细的视频](https://www.youtube.com/watch?v=qvkppppy9K8&list=PLWBKAf81pmOaP9naRiNAqug6EBnkPakvY)，这些都是非常有价值的。
>
> 所以，现在你已经学会了这些，为什么不建立一些伟大的东西呢？

---

# A logical calculus of the ideas immanent in nervous activity

[source link](https://www.cs.cmu.edu/~./epxing/Class/10715/reading/McCulloch.and.Pitts.pdf)

author: Warren S. McCulloch & Walter Pitts

Because of the "all-or-none" character of nervous activity, neural events and the relationship among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.

> 因为神经的活动的“全或无”的特征，神经系统事件和它们之间的关系可以用命题逻辑的方式来处理。人们发现，每个网的行为都可以用这些术语来描述，对含有圆的网增加了更复杂的逻辑手段。而对于任何满足某些条件的逻辑表达式，我们可以找到一个以它所描述的方式行事的网。它表明，在可能的神经生理学假设中的许多特定选择是等价的，在这个意义上，对于每一个在一个假设下表现的网，存在另一个在另一个假设下表现的网，并给出同样的结果，尽管可能不是在同一时间。讨论了该计算法的各种应用。

## Introduction

Theoretical neurophysiology rests on certain cardinal assumptions. The nervous system is a net of neurons, each having a soma and an axon. Their adjunction, or synapses, are always between the axon of one neuron and the soma of another. At any instant a neuron has some threshold, which excitation must exceed to initiate and impulse. This, except for the fact and the time of its occurence, is determined by the neuron, not by the excitation. From the point of excitation the impulse is propagated to all parts of the neuron.

> 理论上的神经生理学建立在某些基本的假设之上。神经系统是一个由神经元组成的网，每个神经元都有一个体细胞和一个轴突。它们的连接点或突触总是在一个神经元的轴突和另一个神经元的体细胞之间。在任何时候，一个神经元都有一些**阈值**，激励必须超过这个阈值才能启动和冲动。这一点，除了其发生的事实和时间外，是由神经元决定的，而不是由兴奋决定的。从激发点开始，脉冲被传播到神经元的所有部分。
