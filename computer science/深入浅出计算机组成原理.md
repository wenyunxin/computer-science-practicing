[toc]

# 入门篇

## 为什么要学习计算机组成原理？

### 计算机底层知识的“第一课”

- 计算机底层原理，构建知识体系，带来长线回报

- 计算机组成原理是计算机硬件和软件之间的桥梁

- 组成原理是计算机其他核心课程的一个“导引”：

  > 向下可以学习数字电路相关的课程，
  >
  > 向上可以学习编译原理、操作系统这些核心课程

- 组成原理是计算机体系结构的一个入门版本

- 比如明白高级语言是如何对应着CPU能够处理的一条条指令，打开编译原理这扇门
- 搞清楚程序是如何加载运行的，能够对操作系统有更深入的理解
- 对整个软件开发领域的全貌有一个系统了解，带来更多的职业发展机会

### 理论和实践相结合

- 了解计算机硬件的发展历史
- Coursera上面的北京大学《计算机组成》开放课
- 图灵奖作者写的《计算机组成与设计：硬件/软件接口》
- 知识广，组成原理中的概念非常多，每个概念的信息量也非常大
- 知识深，组成原理中的很多概念，阐述开来就是计算机学科的另外一门核心课程
- 从为什么的角度去理解这些知识点
- 和日常生活工作的例子相结合，理解计算机的各个组件是怎么运作的
- 通过指令、计算、CPU、存储系统和I/O串起来

---

## 冯·诺依曼体系结构：计算机组成的金字塔

### 计算机的基本硬件组成

- 三大件：CPU、内存和主板
- CPU：central processing unit，计算机的所有“计算”都是由CPU来进行
- 内存：memory。撰写的程序、打开的浏览器、运行的有效都要加载到内存里才能运行
- 主板：motherboard。主板的芯片组(chipset)和总线(bus)解决CPU和内存之间如何通信的问题。芯片组控制了数据传输的流转，也就是数据从哪里到哪里的问题。总线则是实际数据传输的高速公路。因此，总线速度（bus speed）决定了数据能传输得多快。
- 有大三件，配上电源计算机差不多就可以跑起来
- 输入(input)/输出(out)设备，即I/O设备。输入设备：鼠标和键盘，输出设备：显示器
- 硬盘：各种数据持久地保存下来
- 外置显卡：GPU(Graphics Processing Unit)，图形处理器，一样可以做各种“计算”的工作
- I/O设备通过主板上的**南桥**(SouthBridge)芯片组来控制和CPU之间的通信

### 冯·诺依曼体系结构

- 手机制造商们选择把 CPU、内存、网络通信，乃至摄像头芯片，都封装到一个芯片，然后再嵌入到手机主板上。这种方式叫 **SoC**，也就是 System on a Chip（系统芯片）
- 存储程序计算机，暗含两个概念：“可编程”计算机，“存储”计算机
- “不可编程”计算机的代表：老式计算器。由各种门电路组合而成的，然后通过组装出一个固定的电路板，来完成一个特定的计算程序。一旦需要修改功能，就要重新组装电路。程序在计算机硬件层面是“写死”的
- 存储”计算机。这其实是说，程序本身是存储在计算机的内存里，可以通过加载不同的程序来解决不同的问题
- [Von Neumann divides it into six major subdivisions](https://en.wikipedia.org/wiki/First_Draft_of_a_Report_on_the_EDVAC): a **central arithmetic** part, CA, a central control part, CC, memory, M, input, I, output, O, and (slow) external memory, R,
- **First Draft**说明一台计算机应该有哪些部分组成：首先是一个包含算术逻辑单元（Arithmetic Logic Unit，ALU）和处理器寄存器（Processor Register）的处理器单元（Processing Unit），用来完成各种算术和逻辑运算。
- 然后是一个包含指令寄存器（Instruction Register）和程序计数器（Program Counter）的控制器单元（Control Unit/CU），用来控制程序的流程，通常就是不同条件下的分支和跳转
- 在现在的计算机里，上面的**算术逻辑单元和这里的控制器单元，共同组成了我们说的 CPU**
- 接着是用来存储数据（Data）和指令（Instruction）的内存（memory）。以及更大容量的外部存储，在过去，可能是磁带、磁鼓这样的设备，现在通常就是硬盘
- 最后就是各种输入和输出设备，以及对应的输入和输出机制
- 任何一台计算机的任何一个部件都可以归到**运算器**、**控制器**、**存储器**、**输入设备和输出设备**中，而所有的现代计算机也都是基于这个基础架构来设计开发的
- 而所有的计算机程序，也都可以抽象为从输入设备读取输入信息，通过运算器和控制器来执行存储在存储器里的程序，最终把结果输出到输出设备中

---

冯·诺依曼体系结构确立了我们现在每天使用的计算机硬件的基础架构。因此，学习计算机组成原理，其实就是学习和拆解冯·诺依曼体系结构

> [CPU](https://en.wikipedia.org/wiki/Central_processing_unit):
>
> - Processing Unit（处理器单元）
>   - Arithmetic Logic Unit (ALU，算术逻辑单元)
>   - Processor Register (PR，处理器寄存器)
>
> - Control Unit（控制器单元）
>   - Instruction Register（指令寄存器）
>   - Program Counter（程序计数器）
>
> Memory（[RAM](https://en.wikipedia.org/wiki/Random-access_memory): Random-Access Memory）:
>
> - store Data and Instruction
>
> External memory: hard dish, SSD etc...
>
> [Input](https://en.wikipedia.org/wiki/Input_(computer_science)) & [Output](https://en.wikipedia.org/wiki/Input/output)

学习计算机组成原理，就是学习“控制器、运算器的工作原理，也就是 CPU 是怎么工作的，以及为何这样设计；学习内存的工作原理，从最基本的电路，到上层抽象给到 CPU 乃至应用程序的接口是怎样的；学习 CPU 是怎么和输入设备、输出设备打交道的。

学习组成原理，就是在理解从控制器、运算器、存储器、输入设备以及输出设备，从电路这样的硬件，到最终开放给软件的**接口**，是**怎么运作**的，**为什么要设计成这样**，以及在软件开发层面怎么尽可能用好它。”

### 扩展阅读：

- [First Draft of a Report on the EDVAC](https://en.wikipedia.org/wiki/First_Draft_of_a_Report_on_the_EDVAC)
- [Turing Machine](https://en.wikipedia.org/wiki/Turing_machine)

---

## 计算机组成原理学习知识地图

整个计算机组成原理，就是围绕着计算机是如何组织运作展开的

### 知识地图

- 计算机的基本组成：运算器、控制器、存储器、输入设备和输出设备；性能；功耗
- 计算机的指令和计算：编译器和汇编器、操作系统；由控制器来控制的；掌握浮点数
- CPU设计：CPU时钟、数据通路
- 存储器的原理：CPU高速缓存、内存、SSD硬盘和机械硬盘

### 学习组成原理的方法

- 学会提问自己来串联知识点
- 写一些示例程序来验证知识点
- 通过和计算机硬件发展的历史做对照

### 入门书籍

- 对知识地图的核心内容记下来
- 《计算机是怎样跑起来的》
- 《程序是怎样跑起来的》
- Coursera的[《Computer Organization》](https://www.coursera.org/learn/jisuanji-zucheng)，学习相应章节的时候去浏览一遍

### 深入书籍

- 《计算机组成与设计：硬件 / 软件接口》和经典的《深入理解计算机系统》
- 配套视频[B站](https://www.bilibili.com/video/av24540152/?vd_source=0e5acab5147017a01775d15356db9209)和YouTube
- 操作系统大神塔能鲍姆（Andrew S. Tanenbaum）的《计算机组成：结构化方法》。这本书的组织结构和其他教材都不太一样，适合作为一个辅助的参考书来使用。
- 计算机体系结构的兴趣，你还可以深入读一读《计算机体系结构：量化研究方法》

### 课外阅读

在上面这些教材之外，对于资深程序员来说，来自 Redhat 的 What Every Programmer Should Know About Memory 是写出高性能程序不可不读的经典材料。而 LMAX 开源的 Disruptor，则是通过实际应用程序，来理解计算机组成原理中各个知识点的最好范例了。《编码：隐匿在计算机软硬件背后的语言》和《程序员的自我修养：链接、装载和库》是理解计算机硬件和操作系统层面代码执行的优秀阅读材料

### 总结

不是短时间冲刺，而是有节奏地坚持，希望你能够和专栏的发布节奏同步推进，做好思考题，并且多在留言区和其他朋友一起交流，就更容易能够“积小步而至千里”。

## [性能](https://en.wikipedia.org/wiki/Computer_performance)——通过CPU主频来理解

### 什么是性能

指标一：响应时间（Response time）或者执行时间（Execution time）

实际系统里性能监测工具NewRelic

指标二：吞吐率（Throughput）或者带宽（Bandwidth）

性能定义为响应时间的倒数，即，性能 = 1/ 响应时间

[SPEC测试CPU的标准表](https://www.spec.org/cpu2017/results/cpu2017.html)

### 计算机的计时单位：CPU时钟

程序实际花费的 CPU 执行时间（CPU Time），就是 user time 加上 sys time

除了 CPU 之外，时间这个性能指标还会受到主板、内存这些其他相关硬件的影响。所以，我们需要对“时间”这个我们可以感知的指标进行拆解，把程序的 CPU 执行时间变成 CPU 时钟周期数（CPU Cycles）和 时钟周期时间（Clock Cycle）的乘积。

> 程序的 CPU 执行时间 =CPU 时钟周期数×CPU时钟周期时间

CPU时钟周期时间（Clock Cycle）=1/CPU主频

CPU时钟周期时间由CPU的硬件决定，这是软件工程师无法控制的事情，把目光放在优化CPU时钟周期数。

分解CPU时钟周期数：

> 指令数×每条指令的平均时钟周期数（Cycles Per Instruction，简称CPI）

程序的 CPU 执行时间就可以变成这样三个部分的乘积

> 程序的 CPU 执行时间 = 指令数×CPI×Clock Cycle Time

解决性能问题，其实就是要优化这三者。

> 1. **时钟周期时间**，就是计算机主频，这个取决于**计算机硬件**。我们所熟知的摩尔定律就一直在不停地提高我们计算机的主频。比如说，我最早使用的 80386 主频只有 33MHz，现在手头的笔记本电脑就有 2.8GHz，在主频层面，就提升了将近 100 倍。
> 2. 每条指令的平均时钟周期数 CPI，就是**一条指令到底需要多少 CPU Cycle**。在后面讲解 CPU 结构的时候，我们会看到，现代的 CPU 通过流水线技术（**Pipeline**），让一条指令需要的 CPU Cycle 尽可能地少。因此，对于 CPI 的优化，也是计算机组成和体系结构中的重要一环。
> 3. 指令数，代表执行我们的**程序到底需要多少条指令、用哪些指令**。这个很多时候就把挑战交给了**编译器**。同样的代码，编译成计算机指令时候，就有各种不同的表示方式。

类比：我们可以把自己想象成一个 CPU，坐在那里写程序。计算机主频就好像是你的打字速度，打字越快，你自然可以多写一点程序。**CPI** （每条指令的平均时钟周期数Cycles Per Instruction，简称 CPI）相当于你在写程序的时候，熟悉各种快捷键，越是打同样的内容，需要敲击键盘的次数就越少。**指令数**相当于你的程序设计得够合理，同样的程序要写的代码行数就少。如果三者皆能实现，你自然可以很快地写出一个优秀的程序，你的“性能”从外面来看就是好的。

优化计算机性能的三条路径：

> 提升计算机主频，（硬件提升时钟周期时间clock cycle time）
>
> 优化 CPU 设计使得在单个时钟周期内能够执行更多指令，（CPU架构层面，提升CPI）
>
> 以及通过**编译器**来减少需要的指令数。（**软件设计层面**）

## 从哪些方面提升“性能”，功耗墙

CPU性能公式：

> 程序的 CPU 执行时间 = 指令数×CPI×Clock Cycle Time

早期主要是通过提高CPU的晶体管数量（即提升Clock Cycle Time）来提升CPU性能，这就是著名的[摩尔定律](https://en.wikipedia.org/wiki/Moore's_law)就是在该应用场景的背景下提出的。

### 功耗：CPU的“人体极限”

问题背景：奔腾 4 的主频为什么没能超过 3.8GHz 的障碍呢？答案就是功耗问题。

CPU硬件层面的实质：CPU，被叫做**超大规模集成电路**（Very-Large-Scale Integration, VLSI）。这些电路，实际上都是一个个晶体管组合而成的。CPU 在计算，其实就是让晶体管里面的“开关”不断地去“打开”和“关闭”，来组合完成各种运算和功能。

想要计算得快，一方面（**架构层面**，增加pipeline？），我们要在 CPU 里，同样的面积里面，多放一些晶体管，也就是**增加密度**；另一方面（**时钟周期时间的硬件层面**），我们要让晶体管“打开”和“关闭”得更快一点，也就是**提升主频**。而这两者，都会增加功耗，带来耗电和散热的问题

在 CPU 里面，能够放下的晶体管数量和晶体管的“开关”频率也都是有限的。一个 CPU 的功率，可以用这样一个公式来表示：

> 功耗 ~= 1/2 ×负载电容×电压的平方×开关频率×晶体管数量

"那么，为了要提升性能，我们需要不断地增加晶体管数量。同样的面积下，我们想要多放一点晶体管，就要把晶体管造得小一点。这个就是平时我们所说的提升“制程”。从 28nm 到 7nm，相当于晶体管本身变成了原来的 1/4 大小。这个就相当于我们在工厂里，同样的活儿，我们要找瘦小一点的工人，这样一个工厂里面就可以多一些人。我们还要提升主频，让开关的频率变快，也就是要找手脚更快的工人。"

"但是，功耗增加太多，就会导致 CPU 散热跟不上，这时，我们就需要**降低电压**。这里有一点非常关键，在整个功耗的公式里面，功耗和电压的平方是成正比的。这意味着电压下降到原来的 1/5，整个的功耗会变成原来的 1/25。"

### 并行优化，理解[阿姆达尔定律](https://en.wikipedia.org/wiki/Amdahl's_law)

多核CPU方案：“现在 CPU 的性能就是提升了 2 倍乃至 8 倍、16 倍。这也是一个最常见的提升性能的方式，**通过并行提高性能**。”

“这个思想在很多地方都可以使用。举个例子，我们做机器学习程序的时候，需要计算向量的点积，比如向量 W=[W0,W1,W2,…,W15] 和向量 X=[X0,X1,X2,…,X15]，W⋅X=W0∗X0+W1∗X1+ W2∗X2+…+W15∗X15。这些式子由 16 个乘法和 1 个连加组成。如果你自己一个人用笔来算的话，需要一步一步算 16 次乘法和 15 次加法。如果这个时候我们把这个任务分配给 4 个人，同时去算 W0～W3, W4～W7, W8～W11, W12～W15 这样四个部分的结果，再由一个人进行汇总，需要的时间就会缩短。”

“需要满足这样几个条件。

第一，需要进行的计算，本身可以分解成几个可以并行的任务。好比上面的乘法和加法计算，几个人可以同时进行，不会影响最后的结果。

第二，需要能够分解好问题，并确保几个人的结果能够汇总到一起。

第三，在“汇总”这个阶段，是没有办法并行进行的，还是得顺序执行，一步一步来。”

阿姆达尔定律（Amdahl’s Law）。这个定律说的就是，对于一个程序进行优化之后，处理器并行运算之后效率提升的情况。具体可以用这样一个公式来表示：

> 优化后的执行时间 = 受优化影响的执行时间 / 加速倍数 + 不受影响的执行时间

“比如上面的各个向量的一小段的点积，需要 100ns，加法需要 20ns，总共需要 120ns。这里通过并行 4 个 CPU 有了 4 倍的加速度。那么最终优化后，就有了 100/4+20=45ns。即使我们增加更多的并行度来提供加速倍数，比如有 100 个 CPU，整个时间也需要 100/100+20=21ns。”

### 总结延伸

在“摩尔定律”和“并行计算”之外，在整个计算机组成层面，还有这样几个原则性的性能提升方法。

1.**加速大概率事件**。最典型的就是，过去几年流行的深度学习，整个计算过程中，99% 都是向量和矩阵计算，于是，工程师们通过用 GPU 替代 CPU，大幅度提升了深度学习的模型训练过程。本来一个 CPU 需要跑几小时甚至几天的程序，GPU 只需要几分钟就好了。Google 更是不满足于 GPU 的性能，进一步地推出了 TPU。后面的文章，我也会为你讲解 GPU 和 TPU 的基本构造和原理。

2.**通过流水线提高性能**。现代的工厂里的生产线叫“流水线”。我们可以把装配 iPhone 这样的任务拆分成一个个细分的任务，让每个人都只需要处理一道工序，最大化整个工厂的生产效率。类似的，我们的 CPU 其实就是一个“运算工厂”。我们把 CPU 指令执行的过程进行拆分，细化运行，也是现代 CPU 在主频没有办法提升那么多的情况下，性能仍然可以得到提升的重要原因之一。我们在后面也会讲到，现代 CPU 里是如何通过流水线来提升性能的，以及反面的，过长的流水线会带来什么新的功耗和效率上的负面影响。

3.**通过预测提高性能**。通过预先猜测下一步该干什么，而不是等上一步运行的结果，提前进行运算，也是让程序跑得更快一点的办法。典型的例子就是在一个循环访问数组的时候，凭经验，你也会猜到下一步我们会访问数组的下一项。后面要讲的“分支和冒险”、“局部性原理”这些 CPU 和存储系统设计方法，其实都是在利用我们对于未来的“预测”，提前进行相应的操作，来提升我们的程序性能。

### 补充阅读

1.《计算机组成与设计：软 / 硬件接口》（第 5 版）的 1.7 和 1.10 节，也简单介绍了功耗墙和阿姆达尔定律，你可以拿来细细阅读。

2. 如果你想对**阿姆达尔定律**有个更细致的了解，《深入理解计算机系统》（第 3 版）的 1.9 节不容错过。

# 原理篇：指令和运算

## 计算机指令：让我们试试用纸带编程

### 在软硬件接口中，CPU帮我们做了什么事？

“从软件工程师的角度来讲，CPU 就是一个执行各种计算机指令（**Instruction Code**）的逻辑机器。这里的计算机指令，就好比一门 CPU 能够听得懂的语言，我们也可以把它叫作机器语言（**Machine Language**）。”

CPU支持的语言，就是**计算机指令集**（Instruction Set）。通常PC和手机的CPU各自使用不同的两种**计算机指令集**（Instruction Set）。

“CPU 里不能一直放着所有指令，所以计算机程序平时是存储在存储器中的。这种程序指令存储在存储器里面的计算机，我们就叫作存储程序型计算机（Stored-program Computer）。”

### 从编译到汇编，代码怎么变成机器码？

```c
// test.c
int main()
{
  int a = 1; 
  int b = 2;
  a = a + b;
}
```

"要让这段程序在一个 Linux 操作系统上跑起来，我们需要把整个程序翻译成一个汇编语言（ASM，Assembly Language）的程序，这个过程我们一般叫编译（Compile）成汇编代码。"

"针对汇编代码，我们可以再用汇编器（Assembler）翻译成机器码（Machine Code）。这些机器码由“0”和“1”组成的机器语言表示。这一条条机器码，就是一条条的计算机指令。这样一串串的 16 进制数字，就是我们 CPU 能够真正认识的计算机指令。"

程序指令（Instruction）——> Compile into Assemble Code with Assemble Language（用汇编语言编译成**汇编代码**）——> Translate into Machine Code with Assembler（用汇编器翻译成**机器码**）

“汇编代码其实就是“给程序员看的机器码”，也正因为这样，机器码和汇编代码是一一对应的。我们人类很容易记住 add、mov 这些用英文表示的指令，而 8b 45 f8 这样的指令，由于很难一下子看明白是在干什么，所以会非常难以记忆。”

“从高级语言到汇编代码，再到机器码，就是一个日常开发程序，最终变成了 CPU 可以执行的计算机指令的过程。”

### 解析指令和机器码

“我们日常用的 Intel CPU，有 2000 条左右的 CPU 指令，常见的指令可以分成五大类。”

> 第一类**是算术类指令**。我们的加减乘除，在 CPU 层面，都会变成一条条算术类指令。
>
> 第二类是**数据传输类指令**。给变量赋值、在内存里读写数据，用的都是数据传输类指令。
>
> 第三类是**逻辑类指令**。逻辑上的与或非，都是这一类指令。
>
> 第四类是**条件分支类指令**。日常我们写的“**if/else**”，其实都是条件分支类指令。
>
> 最后一类是**无条件跳转指令**。写一些大一点的程序，我们常常需要写一些**函数或者方法**。在调用函数的时候，其实就是发起了一个无条件跳转指令。

用MIPS指令集来说明汇编器是怎么把对应的汇编代码，翻译成为机器码的

“MIPS 的指令是一个 32 位的整数，高 6 位叫操作码（Opcode），也就是代表这条指令具体是一条什么样的指令，剩下的 26 位有三种格式，分别是 R、I 和 J。”

“R 指令是一般用来做算术和逻辑操作，里面有读取和写入数据的寄存器的地址。如果是逻辑位移操作，后面还有位移操作的位移量，而最后的功能码，则是在前面的操作码不够的时候，扩展操作码表示对应的具体指令的。I 指令，则通常是用在数据传输、条件分支，以及在运算的时候使用的并非变量还是常数的时候。这个时候，没有了位移量和操作码，也没有了第三个寄存器，而是把这三部分直接合并成了一个地址值或者一个常数。J 指令就是一个跳转指令，高 6 位之外的 26 位都是一个跳转后的地址。”

“我以一个简单的加法算术指令 add t0,s1, $s2, 为例，给你解释。为了方便，我们下面都用十进制来表示对应的代码。对应的 MIPS 指令里 opcode 是 0，rs 代表第一个寄存器 s1 的地址是 17，rt 代表第二个寄存器 s2 的地址是 18，rd 代表目标的临时寄存器 t0 的地址，是 8。因为不是位移操作，所以位移量是 0。把这些数字拼在一起，就变成了一个 MIPS 的加法指令。为了读起来方便，我们一般把对应的二进制数，用 16 进制表示出来。在这里，也就是 0X02324020。这个数字也就是这条指令对应的机器码。”

“除了 C 这样的编译型的语言之外，不管是 Python 这样的解释型语言，还是 Java 这样使用虚拟机的语言，其实最终都是由不同形式的程序，把我们写好的代码，转换成 CPU 能够理解的机器码来执行的。

只是解释型语言，是通过解释器在程序运行的时候逐句翻译，而 Java 这样使用虚拟机的语言，则是由虚拟机对编译出来的中间代码进行解释，或者即时编译成为机器码来最终执行。”

### 推荐阅读

想要对我们日常使用的 Intel CPU 的指令集有所了解，可以参看《计算机组成与设计：软 / 硬件接口》第 5 版的 2.17 小节。

“我们把一个数字在命令行里面打印出来，背后对应的机器码是什么？你可以试试通过 GCC 把这个的汇编代码和机器码打出来”



## 指令跳转：原来if...else就是goto

### CPU是如何执行指令的？

“实际上，一条条计算机指令执行起来非常复杂。好在 CPU 在软件层面已经为我们做好了封装。对于我们这些做软件的程序员来说，我们只要知道，写好的代码变成了指令之后，是一条一条顺序执行的就可以了。”

“逻辑上，我们可以认为，CPU 其实就是由一堆寄存器组成的。而寄存器就是 CPU 内部，由多个触发器（Flip-Flop）或者锁存器（Latches）组成的简单电路。”

“触发器和锁存器，其实就是两种不同原理的数字电路组成的逻辑门。如果想要深入学习的话，你可以学习数字电路的相关课程”

“N 个触发器或者锁存器，就可以组成一个 N 位（Bit）的寄存器，能够保存 N 位的数据。比方说，我们用的 64 位 Intel 服务器，寄存器就是 64 位的。”

“一个 CPU 里面会有很多种不同功能的寄存器。我这里给你介绍三种比较特殊的。”

“一个是 PC 寄存器（**Program Counter Register**），我们也叫指令地址寄存器（Instruction Address Register）。顾名思义，它就是用来存放下一条需要执行的计算机指令的内存地址。”

“第二个是指令寄存器（**Instruction Register**），用来存放当前正在执行的指令。”

“第三个是条件码寄存器（**Status Register**），用里面的一个一个标记位（**Flag**），存放 CPU 进行算术或者逻辑计算的结果。”

“除了这些特殊的寄存器，CPU 里面还有更多用来存储数据和内存地址的寄存器。这样的寄存器通常一类里面不止一个。我们通常根据存放的数据内容来给它们取名字，比如整数寄存器、浮点数寄存器、向量寄存器和地址寄存器等等。有些寄存器既可以存放数据，又能存放地址，我们就叫它通用寄存器。”

“一个程序执行的时候，CPU 会根据 PC 寄存器里的地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。可以看到，一个程序的一条条指令，在内存里面是连续保存的，也会一条条顺序加载”

“而有些特殊指令，比如上一讲我们讲到 J 类指令，也就是跳转指令，会修改 PC 寄存器里面的地址值。这样，下一条要执行的指令就不是从内存里面顺序加载的了。事实上，这些跳转指令的存在，也是我们可以在写程序的时候，使用 if…else 条件语句和 while/for 循环语句的原因。”

### 从if...else来看程序的执行和跳转

“在这里，如果比较的结果是 True，也就是 r == 0，就把零标志条件码（对应的条件码是 ZF，Zero Flag）设置为 1。除了零标志之外，Intel 的 CPU 下还有进位标志（CF，Carry Flag）、符号标志（SF，Sign Flag）以及溢出标志（OF，Overflow Flag），用在不同的判断条件下。”

### 如何通过 if…else 和 goto 来实现循环？

“jle 和 jmp 指令，有点像程序语言里面的 goto 命令，直接指定了一个特定条件下的跳转位置。虽然我们在用高级语言开发程序的时候反对使用 goto，但是实际在机器指令层面，无论是 if…else…也好，还是 for/while 也好，都是用和 goto 相同的跳转到特定指令位置的方式来实现的。”

### 总结

“我们在单条指令的基础上，学习了程序里的多条指令，究竟是怎么样一条一条被执行的。除了简单地通过 PC 寄存器自增的方式顺序执行外，条件码寄存器会记录下当前执行指令的条件判断状态，然后通过跳转指令读取对应的条件码，修改 PC 寄存器内的下一条指令的地址，最终实现 if…else 以及 for/while 这样的程序控制流程。”

“想要在硬件层面实现这个 goto 语句，除了本身需要用来保存下一条指令地址，以及当前正要执行指令的 PC 寄存器、指令寄存器外，我们只需要再增加一个条件码寄存器，来保留条件判断的状态。这样简简单单的三个**寄存器**，就可以实现条件判断和循环重复执行代码的功能。”

### 推荐阅读

《深入理解计算机系统》的第 3 章，详细讲解了 C 语言和 Intel CPU 的汇编语言以及指令的对应关系，以及 Intel CPU 的各种寄存器和指令集。

“Intel 指令集相对于之前的 MIPS 指令集要复杂一些，一方面，所有的指令是变长的，从 1 个字节到 15 个字节不等；另一方面，即使是汇编代码，还有很多针对操作数据的长度不同有不同的后缀。我在这里没有详细解释各个指令的含义，如果你对用 C/C++ 做 Linux 系统层面开发感兴趣，建议你一定好好读一读这一章节。”

“除了 if…else 的条件语句和 for/while 的循环之外，大部分编程语言还有 switch…case 这样的条件跳转语句。switch…case 编译出来的汇编代码也是这样使用 jne 指令进行跳转吗？对应的汇编代码的性能和写很多 if…else 有什么区别呢？你可以试着写一个简单的 C 语言程序，编译成汇编代码看一看。”

感想：寄存器的种类众多，作用挺大。

## 函数调用：为什么会发生stackoverflow?

栈溢出：[stack overflow](https://en.wikipedia.org/wiki/Stack_overflow)

### 为什么我们需要程序栈？

“我们来看 add 函数。可以看到，add 函数编译之后，代码先执行了一条 push 指令和一条 mov 指令；在函数执行结束的时候，又执行了一条 pop 和一条 ret 指令。这四条指令的执行，其实就是在进行我们接下来要讲压栈（Push）和出栈（Pop）操作。”
